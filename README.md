# ğŸ›ï¸ LawBot - Legal QA Pipeline v7.0 (State-of-the-Art)

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-7.0-green.svg)](https://github.com/lawbot-team/lawbot)
[![Pipeline](https://img.shields.io/badge/pipeline-cascaded--reranking-orange.svg)](https://github.com/lawbot-team/lawbot)

> **Há»‡ thá»‘ng há»i-Ä‘Ã¡p phÃ¡p luáº­t thÃ´ng minh cho Viá»‡t Nam**  
> **PhiÃªn báº£n v7.0: NÃ¢ng cáº¥p kiáº¿n trÃºc lÃªn Xáº¿p háº¡ng Äa táº§ng (Cascaded Reranking)**  
> TÃ­ch há»£p cÃ¡c ká»¹ thuáº­t AI tiÃªn tiáº¿n nháº¥t Ä‘á»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Ä‘a

## âœ¨ **TÃNH NÄ‚NG Ná»”I Báº¬T (KEY FEATURES)**

PhiÃªn báº£n nÃ y tÃ­ch há»£p cÃ¡c ká»¹ thuáº­t hÃ ng Ä‘áº§u trong ngÃ nh AI Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t vÃ  Ä‘á»™ chÃ­nh xÃ¡c:

- **Kiáº¿n trÃºc Xáº¿p háº¡ng Äa táº§ng (Cascaded Reranking)**: Má»™t "phá»…u lá»c" 3 táº§ng thÃ´ng minh giÃºp cÃ¢n báº±ng hoÃ n háº£o giá»¯a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c, cho phÃ©p há»‡ thá»‘ng xá»­ lÃ½ hiá»‡u quáº£ má»™t lÆ°á»£ng lá»›n thÃ´ng tin.

- **Domain-Adaptive Pre-training (DAPT)**: Kháº£ nÄƒng "chuyÃªn mÃ´n hÃ³a" model ngÃ´n ngá»¯, biáº¿n PhoBERT tá»« má»™t chuyÃªn gia Ä‘a ngÃ nh thÃ nh má»™t chuyÃªn gia am hiá»ƒu sÃ¢u sáº¯c vá» phÃ¡p luáº­t (PhoBERT-Law).

- **Há»™i Ä‘á»“ng ChuyÃªn gia (Ensemble Reranking)**: Sá»­ dá»¥ng nhiá»u model Cross-Encoder cÃ¹ng tháº©m Ä‘á»‹nh káº¿t quáº£, giÃºp tÄƒng cÆ°á»ng sá»± á»•n Ä‘á»‹nh vÃ  Ä‘á»™ tin cáº­y cho cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng.

- **Khai thÃ¡c Hard Negatives Tá»± Ä‘á»™ng**: Tá»± Ä‘á»™ng "Ä‘Ã o" ra nhá»¯ng vÃ­ dá»¥ há»c khÃ³ nháº¥t, buá»™c AI pháº£i há»c cÃ¡ch phÃ¢n biá»‡t nhá»¯ng khÃ¡c biá»‡t ngá»¯ nghÄ©a tinh vi trong vÄƒn báº£n luáº­t.

- **Pipeline Tá»‘i Æ°u & Bá»n bá»‰**: ToÃ n bá»™ quy trÃ¬nh Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i thÃ nh cÃ¡c bÆ°á»›c logic, dá»… quáº£n lÃ½, Ä‘i kÃ¨m há»‡ thá»‘ng logging, giÃ¡m sÃ¡t tiáº¿n Ä‘á»™ vÃ  kiá»ƒm tra cháº¥t lÆ°á»£ng chuyÃªn nghiá»‡p.

## ğŸ“‹ **Tá»”NG QUAN Há»† THá»NG**

### **LawBot lÃ  gÃ¬?**
LawBot lÃ  má»™t há»‡ thá»‘ng há»i-Ä‘Ã¡p phÃ¡p luáº­t tiÃªn tiáº¿n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho phÃ¡p luáº­t Viá»‡t Nam. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ´ng nghá»‡ AI hiá»‡n Ä‘áº¡i Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» phÃ¡p luáº­t má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  nhanh chÃ³ng.

### **Kiáº¿n trÃºc há»‡ thá»‘ng v7.0 (Cascaded Reranking):**
```
            [CÃ¢u há»i ngÆ°á»i dÃ¹ng]
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Táº§ng 1: Bi-Encoder (Retrieval)            â”‚
â”‚  - TÃ¬m kiáº¿m siÃªu rá»™ng, láº¥y Top 500 á»©ng viÃªn â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Táº§ng 2: MiniLM Reranker (Light Reranking) â”‚
â”‚  - SÃ ng lá»c siÃªu nhanh, chá»n Top 50        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Táº§ng 3: Ensemble Reranker (Strong Reranking)â”‚
â”‚  - Há»™i Ä‘á»“ng chuyÃªn gia tháº©m Ä‘á»‹nh sÃ¢u       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            [Top 5 káº¿t quáº£ chÃ­nh xÃ¡c nháº¥t]
```

### **CÃ¡ch hoáº¡t Ä‘á»™ng:**
1. **ğŸ” Táº§ng 1 (Bi-Encoder)**: TÃ¬m 500 vÄƒn báº£n phÃ¡p luáº­t liÃªn quan nháº¥t
2. **âš¡ Táº§ng 2 (MiniLM-L6)**: Lá»c nhanh xuá»‘ng 50 á»©ng viÃªn cháº¥t lÆ°á»£ng cao
3. **âš–ï¸ Táº§ng 3 (Ensemble)**: Há»™i Ä‘á»“ng chuyÃªn gia tháº©m Ä‘á»‹nh vÃ  chá»n top 5 káº¿t quáº£ chÃ­nh xÃ¡c nháº¥t

## ğŸ¯ **Táº I SAO Cáº¦N LAW BOT? (WHY)**

### **Váº¥n Ä‘á» hiá»‡n táº¡i:**
- âŒ **KhÃ³ tÃ¬m kiáº¿m**: VÄƒn báº£n phÃ¡p luáº­t ráº¥t nhiá»u vÃ  phá»©c táº¡p
- âŒ **Thá»i gian cháº­m**: TÃ¬m kiáº¿m thá»§ cÃ´ng máº¥t nhiá»u thá»i gian
- âŒ **Thiáº¿u chÃ­nh xÃ¡c**: Káº¿t quáº£ tÃ¬m kiáº¿m khÃ´ng Ä‘Ãºng trá»ng tÃ¢m
- âŒ **KhÃ³ hiá»ƒu**: NgÃ´n ngá»¯ phÃ¡p lÃ½ khÃ³ hiá»ƒu vá»›i ngÆ°á»i khÃ´ng chuyÃªn

### **Giáº£i phÃ¡p LawBot v7.0:**
- âœ… **TÃ¬m kiáº¿m nhanh**: AI tÃ¬m kiáº¿m trong vÃ i giÃ¢y
- âœ… **Káº¿t quáº£ chÃ­nh xÃ¡c**: "Phá»…u lá»c" 3 táº§ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Ä‘a
- âœ… **Dá»… hiá»ƒu**: Tráº£ vá» nhá»¯ng Ä‘iá»u luáº­t liÃªn quan trá»±c tiáº¿p nháº¥t
- âœ… **Tiáº¿t kiá»‡m thá»i gian**: Giáº£m thá»i gian tra cá»©u tá»« vÃ i giá» xuá»‘ng cÃ²n vÃ i giÃ¢y

## â° **KHI NÃ€O Sá»¬ Dá»¤NG? (WHEN)**

### **CÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng:**
- ğŸ” **TÃ¬m kiáº¿m luáº­t**: "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
- ğŸ“‹ **Tra cá»©u quy Ä‘á»‹nh**: "Äiá»u kiá»‡n thÃ nh láº­p doanh nghiá»‡p lÃ  gÃ¬?"
- âš–ï¸ **So sÃ¡nh vÄƒn báº£n**: "Sá»± khÃ¡c biá»‡t giá»¯a Luáº­t Doanh nghiá»‡p cÅ© vÃ  má»›i?"
- ğŸ“ **TÃ¬m Ä‘iá»u khoáº£n**: "Äiá»u 113 Bá»™ luáº­t Lao Ä‘á»™ng quy Ä‘á»‹nh gÃ¬?"

### **Khi nÃ o KHÃ”NG sá»­ dá»¥ng:**
- âŒ CÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n phÃ¡p luáº­t
- âŒ YÃªu cáº§u tÆ° váº¥n phÃ¡p lÃ½ chuyÃªn sÃ¢u
- âŒ Thay tháº¿ hoÃ n toÃ n luáº­t sÆ°

## ğŸ“ **Sá»¬ Dá»¤NG á» ÄÃ‚U? (WHERE)**

### **MÃ´i trÆ°á»ng phÃ¡t triá»ƒn:**
- ğŸ’» **Local Development**: MÃ¡y tÃ­nh cÃ¡ nhÃ¢n
- ğŸ–¥ï¸ **Server**: MÃ¡y chá»§ cÃ´ng ty
- â˜ï¸ **Cloud**: AWS, Google Cloud, Azure
- ğŸ³ **Docker**: Container deployment

### **YÃªu cáº§u há»‡ thá»‘ng:**
```
OS: Windows 10+, Ubuntu 18.04+, macOS 10.14+
RAM: Tá»‘i thiá»ƒu 8GB, khuyáº¿n nghá»‹ 16GB+
Storage: Tá»‘i thiá»ƒu 10GB cho models vÃ  data
GPU: NVIDIA GPU vá»›i CUDA (khuyáº¿n nghá»‹)
Python: 3.8+
```

## ğŸ‘¥ **AI CHO? (WHO)**

### **Äá»‘i tÆ°á»£ng sá»­ dá»¥ng:**
- ğŸ‘¨â€ğŸ’¼ **Luáº­t sÆ°**: Tra cá»©u nhanh vÄƒn báº£n phÃ¡p luáº­t
- ğŸ‘¨â€ğŸ’» **NhÃ  phÃ¡t triá»ƒn**: TÃ­ch há»£p vÃ o á»©ng dá»¥ng phÃ¡p lÃ½
- ğŸ‘¨â€ğŸ“ **Sinh viÃªn luáº­t**: Há»c táº­p vÃ  nghiÃªn cá»©u
- ğŸ‘¨â€ğŸ’¼ **Doanh nghiá»‡p**: TuÃ¢n thá»§ quy Ä‘á»‹nh phÃ¡p luáº­t
- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **CÃ´ng dÃ¢n**: TÃ¬m hiá»ƒu quyá»n vÃ  nghÄ©a vá»¥

### **Äá»‘i tÆ°á»£ng phÃ¡t triá»ƒn:**
- ğŸ‘¨â€ğŸ’» **AI/ML Engineers**: PhÃ¡t triá»ƒn vÃ  tá»‘i Æ°u models
- ğŸ‘¨â€ğŸ’» **Software Engineers**: TÃ­ch há»£p vÃ  deployment
- ğŸ‘¨â€ğŸ’» **Data Scientists**: PhÃ¢n tÃ­ch vÃ  cáº£i thiá»‡n performance
- ğŸ‘¨â€ğŸ’» **DevOps Engineers**: Deployment vÃ  monitoring

## ğŸš€ **HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG (QUICK START)**

### **BÆ°á»›c 1: CÃ i Ä‘áº·t MÃ´i trÆ°á»ng**

```bash
# Clone repository
git clone https://github.com/lawbot-team/lawbot.git
cd lawbot

# Táº¡o mÃ´i trÆ°á»ng áº£o
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate     # Windows

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
pip install -r requirements.txt

# (TÃ¹y chá»n) CÃ i Ä‘áº·t thÃªm dependencies cho development
pip install -r requirements-dev.txt
```

### **BÆ°á»›c 2: Cháº¡y ToÃ n bá»™ Pipeline (Má»™t lá»‡nh duy nháº¥t)**

**ğŸ¯ Lá»‡nh khuyáº¿n nghá»‹ - Hiá»‡u suáº¥t cao nháº¥t:**
```bash
python run_pipeline.py
```

**âš¡ Lá»‡nh nhanh - Bá» qua DAPT:**
```bash
python run_pipeline.py --no-dapt
```

**ğŸ”§ CÃ¡c tÃ¹y chá»n khÃ¡c:**
```bash
# Xem danh sÃ¡ch cÃ¡c bÆ°á»›c
python run_pipeline.py --list-steps

# Cháº¡y tá»« bÆ°á»›c cá»¥ thá»ƒ
python run_pipeline.py --step 02

# Bá» qua bÆ°á»›c filtering
python run_pipeline.py --skip-filtering
```

### **BÆ°á»›c 3: Cháº¡y Giao diá»‡n Web App**

Sau khi pipeline hoÃ n táº¥t, khá»Ÿi Ä‘á»™ng giao diá»‡n ngÆ°á»i dÃ¹ng:

```bash
streamlit run app.py
```

Truy cáº­p http://localhost:8501 Ä‘á»ƒ báº¯t Ä‘áº§u sá»­ dá»¥ng.

### **BÆ°á»›c 4: Sá»­ dá»¥ng API**

```python
from core.pipeline import LegalQAPipeline

# Khá»Ÿi táº¡o pipeline
pipeline = LegalQAPipeline()

# Há»i Ä‘Ã¡p
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
results = pipeline.predict(query=query, top_k_retrieval=100, top_k_final=5)

# In káº¿t quáº£
for i, result in enumerate(results):
    print(f"Káº¿t quáº£ {i+1}: {result['aid']}")
    print(f"Äiá»ƒm: {result['rerank_score']:.4f}")
    print(f"Ná»™i dung: {result['content'][:200]}...")
```





## ğŸ“ **Cáº¤U TRÃšC Dá»° ÃN**

```
LawBot/
â”œâ”€â”€ ğŸ“ app/
â”‚   â””â”€â”€ app.py                  # Giao diá»‡n web Streamlit
â”œâ”€â”€ ğŸ“ core/                    # CÃ¡c module vÃ  class cá»‘t lÃµi
â”‚   â”œâ”€â”€ pipeline.py             # Class pipeline xá»­ lÃ½ chÃ­nh (3 táº§ng)
â”‚   â”œâ”€â”€ logging_utils.py        # Há»‡ thá»‘ng ghi log chuyÃªn nghiá»‡p
â”‚   â”œâ”€â”€ evaluation_utils.py     # CÃ´ng cá»¥ Ä‘Ã¡nh giÃ¡ vÃ  táº¡o bÃ¡o cÃ¡o
â”‚   â””â”€â”€ progress_utils.py       # CÃ´ng cá»¥ theo dÃµi tiáº¿n trÃ¬nh
â”œâ”€â”€ ğŸ“ scripts/                 # CÃ¡c ká»‹ch báº£n thá»±c thi pipeline
â”‚   â”œâ”€â”€ 00_adapt_model.py       # (NÃ¢ng cao) Domain-Adaptive Pre-training
â”‚   â”œâ”€â”€ 01_check_environment.py # BÆ°á»›c 1: MÃ´i trÆ°á»ng & SÆ¡ cháº¿
â”‚   â”œâ”€â”€ 02_prepare_training_data.py # BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u training
â”‚   â”œâ”€â”€ 03_train_models.py      # BÆ°á»›c 3: Huáº¥n luyá»‡n & ÄÃ¡nh giÃ¡
â”‚   â””â”€â”€ ğŸ“ utils/               # CÃ¡c script tiá»‡n Ã­ch
â”‚       â”œâ”€â”€ filter_dataset.py   # Logic lá»c dá»¯ liá»‡u
â”‚       â”œâ”€â”€ run_filter.py       # Wrapper Ä‘á»ƒ cháº¡y filter
â”‚       â””â”€â”€ check_project.py    # Kiá»ƒm tra cáº¥u trÃºc dá»± Ã¡n
â”œâ”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“ models/                  # NÆ¡i lÆ°u cÃ¡c model Ä‘Ã£ huáº¥n luyá»‡n
â”‚   â”œâ”€â”€ phobert-law/            # (NÃ¢ng cao) Model chuyÃªn gia phÃ¡p luáº­t
â”‚   â”œâ”€â”€ minilm-l6/              # Model reranker siÃªu nhanh
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ“ indexes/                 # NÆ¡i lÆ°u FAISS index
â”œâ”€â”€ ğŸ“ reports/                 # CÃ¡c bÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡
â”œâ”€â”€ ğŸ“ logs/                    # CÃ¡c file log cá»§a má»—i láº§n cháº¡y
â”œâ”€â”€ ğŸ“„ config.py                # File cáº¥u hÃ¬nh trung tÃ¢m
â”œâ”€â”€ ğŸ“„ run_pipeline.py          # TrÃ¬nh Ä‘iá»u khiá»ƒn pipeline chÃ­nh
â””â”€â”€ ğŸ“„ README.md                # TÃ i liá»‡u hÆ°á»›ng dáº«n
```

## ğŸ› ï¸ **Cáº¤U HÃŒNH & TÃ™Y CHá»ˆNH**

Táº¥t cáº£ cÃ¡c tham sá»‘ quan trá»ng cá»§a há»‡ thá»‘ng Ä‘á»u Ä‘Æ°á»£c quáº£n lÃ½ táº­p trung táº¡i `config.py`. Báº¡n cÃ³ thá»ƒ dá»… dÃ ng thay Ä‘á»•i model, Ä‘iá»u chá»‰nh siÃªu tham sá»‘ huáº¥n luyá»‡n (learning rate, batch size) vÃ  cÃ¡c cÃ i Ä‘áº·t cá»§a pipeline táº¡i Ä‘Ã¢y.

Há»‡ thá»‘ng cÅ©ng há»— trá»£ cáº¥u hÃ¬nh qua **Biáº¿n MÃ´i trÆ°á»ng (Environment Variables)**, ráº¥t há»¯u Ã­ch khi triá»ƒn khai lÃªn server.

### **Environment Variables**

```bash
# Environment
export LAWBOT_ENV=production
export LAWBOT_DEBUG=false

# Directories
export LAWBOT_DATA_DIR=/path/to/data
export LAWBOT_MODELS_DIR=/path/to/models
export LAWBOT_INDEXES_DIR=/path/to/indexes

# Hyperparameters
export LAWBOT_BI_ENCODER_BATCH_SIZE=8
export LAWBOT_CROSS_ENCODER_BATCH_SIZE=4
export LAWBOT_BI_ENCODER_LR=1e-7
export LAWBOT_CROSS_ENCODER_LR=5e-6

# Pipeline settings
export LAWBOT_TOP_K_RETRIEVAL=100
export LAWBOT_TOP_K_FINAL=5
```

### **Configuration File**

```python
import config

# In thÃ´ng tin cáº¥u hÃ¬nh
config.print_config_summary()

# Validate cáº¥u hÃ¬nh
config.validate_config()
```

## ğŸ”„ **LUá»’NG Xá»¬ LÃ NGHIá»†P Vá»¤ CHI TIáº¾T**

### **ğŸ¯ Quy trÃ¬nh xá»­ lÃ½ cÃ¢u há»i phÃ¡p luáº­t:**

#### **1. Tiáº¿p nháº­n cÃ¢u há»i**
- **Input**: NgÆ°á»i dÃ¹ng nháº­p cÃ¢u há»i vá» phÃ¡p luáº­t
- **VÃ­ dá»¥**: "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
- **Xá»­ lÃ½**: Há»‡ thá»‘ng phÃ¢n tÃ­ch vÃ  chuáº©n hÃ³a cÃ¢u há»i

#### **2. Táº§ng 1: TÃ¬m kiáº¿m rá»™ng (Bi-Encoder)**
- **Má»¥c Ä‘Ã­ch**: TÃ¬m 500 vÄƒn báº£n phÃ¡p luáº­t cÃ³ liÃªn quan nháº¥t
- **CÃ¡ch hoáº¡t Ä‘á»™ng**: 
  - Chuyá»ƒn cÃ¢u há»i thÃ nh vector 768 chiá»u
  - So sÃ¡nh vá»›i táº¥t cáº£ vÄƒn báº£n trong kho dá»¯ liá»‡u
  - Tráº£ vá» 500 káº¿t quáº£ cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao nháº¥t
- **Thá»i gian**: ~100ms
- **Äá»™ chÃ­nh xÃ¡c**: ~70% (Precision@5)

#### **3. Táº§ng 2: Lá»c nhanh (MiniLM-L6)**
- **Má»¥c Ä‘Ã­ch**: Lá»c nhanh tá»« 500 xuá»‘ng 50 á»©ng viÃªn cháº¥t lÆ°á»£ng cao
- **CÃ¡ch hoáº¡t Ä‘á»™ng**:
  - Sá»­ dá»¥ng model nhá», nhanh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sÆ¡ bá»™
  - Káº¿t há»£p Ä‘iá»ƒm retrieval vá»›i Ä‘iá»ƒm light reranking
  - Chá»n top 50 á»©ng viÃªn Ä‘á»ƒ Ä‘Æ°a lÃªn táº§ng 3
- **Thá»i gian**: ~150ms
- **LÃ½ do**: Tiáº¿t kiá»‡m thá»i gian cho táº§ng 3

#### **4. Táº§ng 3: Tháº©m Ä‘á»‹nh chuyÃªn sÃ¢u (Ensemble)**
- **Má»¥c Ä‘Ã­ch**: Há»™i Ä‘á»“ng chuyÃªn gia tháº©m Ä‘á»‹nh vÃ  chá»n top 5 káº¿t quáº£
- **CÃ¡ch hoáº¡t Ä‘á»™ng**:
  - Sá»­ dá»¥ng nhiá»u model Cross-Encoder cÃ¹ng lÃºc
  - PhoBERT-Law + XLM-RoBERTa Ä‘Ã¡nh giÃ¡ song song
  - Láº¥y Ä‘iá»ƒm trung bÃ¬nh Ä‘á»ƒ ra quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng
- **Thá»i gian**: ~300ms
- **Äá»™ chÃ­nh xÃ¡c**: >90% (Precision@5)

#### **5. Tráº£ vá» káº¿t quáº£**
- **Output**: 5 vÄƒn báº£n phÃ¡p luáº­t phÃ¹ há»£p nháº¥t
- **ThÃ´ng tin bao gá»“m**:
  - Ná»™i dung Ä‘iá»u luáº­t
  - Äiá»ƒm sá»‘ tá»«ng táº§ng
  - ThÃ´ng tin bá»• sung (náº¿u cÃ³)

### **ğŸ§  Logic nghiá»‡p vá»¥ chi tiáº¿t:**

#### **Táº¡i sao cáº§n 3 táº§ng?**
1. **Táº§ng 1**: KhÃ´ng thá»ƒ bá» qua vÃ¬ cáº§n tÃ¬m kiáº¿m trong toÃ n bá»™ kho dá»¯ liá»‡u
2. **Táº§ng 2**: Cáº§n thiáº¿t Ä‘á»ƒ giáº£m táº£i cho táº§ng 3, trÃ¡nh lÃ£ng phÃ­ tÃ i nguyÃªn
3. **Táº§ng 3**: Cáº§n thiáº¿t Ä‘á»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Ä‘a cho káº¿t quáº£ cuá»‘i cÃ¹ng

#### **CÃ¡ch há»‡ thá»‘ng há»c há»i:**
1. **Hard Negative Mining**: Tá»± Ä‘á»™ng tÃ¬m nhá»¯ng vÃ­ dá»¥ khÃ³ nháº¥t Ä‘á»ƒ model há»c
2. **Domain-Adaptive Pre-training**: ChuyÃªn mÃ´n hÃ³a model cho phÃ¡p luáº­t
3. **Ensemble Learning**: Káº¿t há»£p nhiá»u Ã½ kiáº¿n chuyÃªn gia

#### **Äáº£m báº£o cháº¥t lÆ°á»£ng:**
1. **Validation**: Kiá»ƒm tra káº¿t quáº£ á»Ÿ má»—i táº§ng
2. **Logging**: Ghi láº¡i toÃ n bá»™ quÃ¡ trÃ¬nh Ä‘á»ƒ debug
3. **Monitoring**: Theo dÃµi hiá»‡u suáº¥t real-time

## ğŸ“Š **HIá»†U SUáº¤T Dá»° KIáº¾N**

Vá»›i kiáº¿n trÃºc 3 táº§ng vÃ  cÃ¡c ká»¹ thuáº­t tá»‘i Æ°u, há»‡ thá»‘ng Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng áº¥n tÆ°á»£ng:

### **ğŸ“ˆ Äá»™ chÃ­nh xÃ¡c theo tá»«ng táº§ng:**

| Metric | Táº§ng 1: Retrieval | Táº§ng 2: Light Reranking | Táº§ng 3: Strong Reranking |
|--------|-------------------|-------------------------|---------------------------|
| **Precision@5** | ~70% | ~80% | **> 90%** |
| **Recall@5** | ~60% | ~75% | **> 85%** |
| **MRR** | ~0.7 | ~0.8 | **> 0.85** |

### **âš¡ Thá»i gian xá»­ lÃ½:**

| TÃ¡c vá»¥ | Thá»i gian | MÃ´ táº£ |
|--------|-----------|-------|
| **Táº§ng 1**: Retrieval (500 á»©ng viÃªn) | ~100ms | TÃ¬m kiáº¿m rá»™ng trong toÃ n bá»™ kho dá»¯ liá»‡u |
| **Táº§ng 2**: Light Reranking (50 á»©ng viÃªn) | ~150ms | Lá»c nhanh vá»›i MiniLM-L6 |
| **Táº§ng 3**: Strong Reranking (5 káº¿t quáº£) | ~300ms | Tháº©m Ä‘á»‹nh chuyÃªn sÃ¢u vá»›i Ensemble |
| **ğŸ“Š Tá»•ng thá»i gian pháº£n há»“i** | **~550ms** | **Nhanh hÆ¡n 10x so vá»›i tÃ¬m kiáº¿m thá»§ cÃ´ng** |

### **ğŸ¯ So sÃ¡nh vá»›i phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng:**

| TiÃªu chÃ­ | TÃ¬m kiáº¿m thá»§ cÃ´ng | LawBot v7.0 |
|----------|-------------------|-------------|
| **Thá»i gian** | 2-3 giá» | **30 giÃ¢y** |
| **Äá»™ chÃ­nh xÃ¡c** | 60-70% | **90%+** |
| **Kháº£ nÄƒng má»Ÿ rá»™ng** | Háº¡n cháº¿ | **KhÃ´ng giá»›i háº¡n** |
| **Chi phÃ­** | Cao (nhÃ¢n lá»±c) | **Tháº¥p** |



## ğŸ› ï¸ **PHÃT TRIá»‚N & Báº¢O TRÃŒ**

### **Kiá»ƒm tra cáº¥u trÃºc dá»± Ã¡n:**

```bash
# Kiá»ƒm tra cáº¥u trÃºc vÃ  best practices
python scripts/utils/check_project.py
```

### **Lá»c dá»¯ liá»‡u (náº¿u cáº§n):**

```bash
# Lá»c dá»¯ liá»‡u thÃ´ Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng
python scripts/utils/run_filter.py
```

### **Cháº¡y tá»«ng bÆ°á»›c riÃªng láº»:**

```bash
# BÆ°á»›c 0: DAPT (Domain-Adaptive Pre-training)
python scripts/00_adapt_model.py

# BÆ°á»›c 1: Kiá»ƒm tra mÃ´i trÆ°á»ng vÃ  xá»­ lÃ½ dá»¯ liá»‡u
python scripts/01_check_environment.py

# BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u training
python scripts/02_prepare_training_data.py

# BÆ°á»›c 3: Huáº¥n luyá»‡n models vÃ  Ä‘Ã¡nh giÃ¡
python scripts/03_train_models.py
```

## ğŸ“‹ **HÆ¯á»šNG DáºªN Váº¬N HÃ€NH**

### **CÃ¡c tÃ¡c vá»¥ hÃ ng ngÃ y:**

#### **1. GiÃ¡m sÃ¡t há»‡ thá»‘ng**
```bash
# Kiá»ƒm tra logs
tail -f logs/pipeline.log

# Kiá»ƒm tra hiá»‡u suáº¥t
python scripts/utils/check_performance.py

# Kiá»ƒm tra dung lÆ°á»£ng á»• cá»©ng
df -h
```

#### **2. Sao lÆ°u dá»¯ liá»‡u**
```bash
# Sao lÆ°u models
tar -czf models_backup_$(date +%Y%m%d).tar.gz models/

# Sao lÆ°u dá»¯ liá»‡u
tar -czf data_backup_$(date +%Y%m%d).tar.gz data/

# Sao lÆ°u indexes
tar -czf indexes_backup_$(date +%Y%m%d).tar.gz indexes/
```

#### **3. Báº£o trÃ¬ há»‡ thá»‘ng**
```bash
# Dá»n dáº¹p logs cÅ©
find logs/ -name "*.log" -mtime +30 -delete

# Dá»n dáº¹p checkpoints cÅ©
find checkpoints/ -name "*.pt" -mtime +7 -delete

# Cáº­p nháº­t dependencies
pip install -r requirements.txt --upgrade
```

### **Danh sÃ¡ch triá»ƒn khai:**

#### **1. TrÆ°á»›c khi triá»ƒn khai**
- [ ] Táº¥t cáº£ tests Ä‘á»u pass
- [ ] Code Ä‘Ã£ Ä‘Æ°á»£c review vÃ  approve
- [ ] Documentation Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t
- [ ] Performance benchmarks Ä‘áº¡t yÃªu cáº§u
- [ ] Security scan hoÃ n táº¥t

#### **2. Triá»ƒn khai**
- [ ] Sao lÆ°u phiÃªn báº£n hiá»‡n táº¡i
- [ ] Triá»ƒn khai phiÃªn báº£n má»›i
- [ ] Cháº¡y health checks
- [ ] GiÃ¡m sÃ¡t lá»—i
- [ ] XÃ¡c minh chá»©c nÄƒng

#### **3. Sau khi triá»ƒn khai**
- [ ] GiÃ¡m sÃ¡t performance metrics
- [ ] Kiá»ƒm tra feedback ngÆ°á»i dÃ¹ng
- [ ] Cáº­p nháº­t monitoring alerts
- [ ] Ghi láº¡i cÃ¡c váº¥n Ä‘á»

### **Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t:**

#### **1. Tá»‘i Æ°u Model**
```python
# Tá»‘i Æ°u Bi-Encoder
config.BI_ENCODER_BATCH_SIZE = 16  # TÄƒng náº¿u GPU memory cho phÃ©p
config.BI_ENCODER_LR = 2e-5        # Äiá»u chá»‰nh learning rate

# Tá»‘i Æ°u Cross-Encoder
config.CROSS_ENCODER_BATCH_SIZE = 8
config.CROSS_ENCODER_LR = 1e-5
```

#### **2. Tá»‘i Æ°u há»‡ thá»‘ng**
```bash
# TÄƒng file descriptors
ulimit -n 65536

# Tá»‘i Æ°u memory usage
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# Báº­t mixed precision
export CUDA_LAUNCH_BLOCKING=1
```

#### **3. Tá»‘i Æ°u FAISS Index**
```python
# FAISS index optimization
faiss.omp_set_num_threads(8)  # Set sá»‘ threads
index.nprobe = 64             # Äiá»u chá»‰nh search parameters
```

### **Kiá»ƒm tra cáº¥u trÃºc dá»± Ã¡n:**

```bash
# Kiá»ƒm tra cáº¥u trÃºc project vÃ  best practices
python scripts/utils/check_project.py
```

## ğŸ“š **API DOCUMENTATION**

### **LegalQAPipeline**

Class chÃ­nh Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i há»‡ thá»‘ng.

```python
from core.pipeline import LegalQAPipeline

# Khá»Ÿi táº¡o
pipeline = LegalQAPipeline()

# Kiá»ƒm tra tráº¡ng thÃ¡i
if pipeline.is_ready:
    print("Pipeline sáºµn sÃ ng!")
else:
    print("Pipeline chÆ°a sáºµn sÃ ng!")
```

#### **Methods:**

##### `predict(query, top_k_retrieval=100, top_k_final=5)`

Dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i cho cÃ¢u há»i.

**Parameters:**
- `query` (str): CÃ¢u há»i cáº§n tráº£ lá»i
- `top_k_retrieval` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£ retrieval (default: 100)
- `top_k_final` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£ cuá»‘i cÃ¹ng (default: 5)

**Returns:**
- `List[Dict]`: Danh sÃ¡ch káº¿t quáº£ vá»›i format:
  ```python
  [
      {
          "aid": "law_1_113",
          "content": "Äiá»u 113: NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
          "retrieval_score": 0.85,
          "rerank_score": 0.92
      },
      # ...
  ]
  ```

**VÃ­ dá»¥ sá»­ dá»¥ng:**
```python
# Input
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"

# Output
results = [
    {
        "aid": "law_1_113",
        "content": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm 12 ngÃ y lÃ m viá»‡c...",
        "retrieval_score": 0.85,
        "rerank_score": 0.92
    },
    {
        "aid": "law_1_114",
        "content": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm Ä‘Æ°á»£c tÃ­nh theo nÄƒm lÃ m viá»‡c...",
        "retrieval_score": 0.78,
        "rerank_score": 0.87
    }
]
```

##### `retrieve(query, top_k=100)`

Chá»‰ thá»±c hiá»‡n retrieval (táº§ng 1).

**Parameters:**
- `query` (str): CÃ¢u há»i
- `top_k` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£

**Returns:**
- `Tuple[List[str], List[float]]`: (aids, scores)

**VÃ­ dá»¥:**
```python
# Input
query = "Äiá»u kiá»‡n thÃ nh láº­p doanh nghiá»‡p?"

# Output
aids = ["law_2_15", "law_2_16", "law_2_17", ...]
scores = [0.95, 0.87, 0.82, ...]
```

##### `rerank(query, retrieved_aids, retrieved_distances)`

Chá»‰ thá»±c hiá»‡n reranking (táº§ng 2).

**Parameters:**
- `query` (str): CÃ¢u há»i
- `retrieved_aids` (List[str]): Danh sÃ¡ch AIDs tá»« retrieval
- `retrieved_distances` (List[float]): Äiá»ƒm sá»‘ tá»« retrieval

**Returns:**
- `List[Dict]`: Káº¿t quáº£ Ä‘Ã£ rerank

**VÃ­ dá»¥:**
```python
# Input
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
retrieved_aids = ["law_1_113", "law_1_114", "law_1_115"]
retrieved_distances = [0.85, 0.78, 0.72]

# Output
reranked_results = [
    {
        "aid": "law_1_113",
        "content": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
        "retrieval_score": 0.85,
        "rerank_score": 0.92
    },
    {
        "aid": "law_1_114", 
        "content": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm...",
        "retrieval_score": 0.78,
        "rerank_score": 0.87
    }
]
```

## ğŸ› ï¸ **UTILITIES**

### **Dataset Filtering Utility**

Script Ä‘á»ƒ lá»c dataset trÆ°á»›c khi cháº¡y pipeline chÃ­nh:

```bash
# Cháº¡y filtering utility
python scripts/utils/run_filter.py

# Hoáº·c cháº¡y trá»±c tiáº¿p
python scripts/utils/filter_dataset.py
```

**Chá»©c nÄƒng:**
- Lá»c bá» samples cÃ³ ground truth khÃ´ng phÃ¹ há»£p
- Giá»¯ láº¡i ~100-200 samples cháº¥t lÆ°á»£ng cao
- Cáº£i thiá»‡n cháº¥t lÆ°á»£ng dá»¯ liá»‡u training

### **Project Structure Checker**

Kiá»ƒm tra cáº¥u trÃºc project vÃ  best practices:

```bash
python scripts/utils/check_project.py
```

**Chá»©c nÄƒng:**
- Kiá»ƒm tra cáº¥u trÃºc thÆ° má»¥c
- Validate naming conventions
- Kiá»ƒm tra documentation
- Äáº£m báº£o best practices

## ğŸ› ï¸ **DEVELOPMENT & BEST PRACTICES**

### **Project Structure Check:**

```bash
# Kiá»ƒm tra cáº¥u trÃºc project vÃ  best practices
python scripts/utils/check_project.py
```

### **Code Quality Standards:**

```bash
# Format code
black .

# Lint code
flake8 .

# Type checking
mypy .

# Run tests
pytest tests/
```

### **Best Practices Applied:**

#### **1. Separation of Concerns**
- **Pipeline Scripts**: Má»—i script cÃ³ má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ
- **Utility Scripts**: TÃ¡ch riÃªng vÃ o thÆ° má»¥c `scripts/utils/`
- **Core Modules**: TÃ¡ch biá»‡t logic nghiá»‡p vá»¥ vÃ  infrastructure

#### **2. Naming Conventions**
- **Pipeline Steps**: `01_`, `02_`, `03_` prefix cho cÃ¡c bÆ°á»›c chÃ­nh
- **Utility Scripts**: TÃªn mÃ´ táº£ rÃµ chá»©c nÄƒng
- **Functions**: snake_case cho Python functions
- **Classes**: PascalCase cho class names

#### **3. Error Handling**
- **Graceful Degradation**: Há»‡ thá»‘ng váº«n hoáº¡t Ä‘á»™ng khi cÃ³ lá»—i
- **Detailed Logging**: Log Ä‘áº§y Ä‘á»§ thÃ´ng tin lá»—i
- **User-Friendly Messages**: ThÃ´ng bÃ¡o lá»—i dá»… hiá»ƒu

#### **4. Configuration Management**
- **Environment Variables**: Há»— trá»£ cáº¥u hÃ¬nh qua env vars
- **Centralized Config**: Táº¥t cáº£ config trong `config.py`
- **Validation**: Kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a config

### **Performance Optimization:**

#### **1. Memory Management**
- **Batch Processing**: Xá»­ lÃ½ theo batch Ä‘á»ƒ tiáº¿t kiá»‡m memory
- **GPU Utilization**: Tá»‘i Æ°u sá»­ dá»¥ng GPU
- **Model Caching**: Cache models Ä‘á»ƒ trÃ¡nh load láº¡i

#### **2. Speed Optimization**
- **FAISS Index**: Sá»­ dá»¥ng FAISS cho retrieval nhanh
- **Parallel Processing**: Xá»­ lÃ½ song song khi cÃ³ thá»ƒ
- **Efficient Data Structures**: Sá»­ dá»¥ng cáº¥u trÃºc dá»¯ liá»‡u hiá»‡u quáº£

## ğŸ”„ **TECHNICAL ARCHITECTURE DETAILS**

### **Core Components:**

#### **1. Bi-Encoder (Retrieval Layer)**
```python
# Model: bkai-foundation-models/vietnamese-bi-encoder
# Purpose: Encode questions and documents into vectors
# Output: 768-dimensional embeddings
# Usage: FAISS similarity search

class BiEncoderComponent:
    def encode(self, texts: List[str]) -> np.ndarray:
        """Encode texts to embeddings"""
        embeddings = self.model.encode(texts, convert_to_tensor=True)
        return embeddings.cpu().numpy()
    
    def search(self, query_embedding: np.ndarray, top_k: int) -> Tuple[List[int], List[float]]:
        """Search similar documents using FAISS"""
        distances, indices = self.faiss_index.search(query_embedding, top_k)
        return indices, distances
```

#### **2. Cross-Encoder (Reranking Layer)**
```python
# Model: vinai/phobert-large
# Purpose: Score question-document pairs
# Input: [CLS] question [SEP] document [SEP]
# Output: Binary classification score (0-1)

class CrossEncoderComponent:
    def score_pairs(self, pairs: List[List[str]]) -> List[float]:
        """Score question-document pairs"""
        tokenized = self.tokenizer(
            pairs,
            padding=True,
            truncation=True,
            max_length=256,
            return_tensors="pt"
        )
        
        with torch.no_grad():
            logits = self.model(**tokenized).logits
            scores = torch.softmax(logits, dim=1)[:, 1].cpu().tolist()
        
        return scores
```

#### **3. FAISS Index**
```python
# Type: IndexFlatIP (Inner Product)
# Dimension: 768
# Normalization: L2 normalization
# Size: ~100MB for 100K documents

class FAISSIndex:
    def __init__(self, dimension: int = 768):
        self.index = faiss.IndexFlatIP(dimension)
        self.index_to_aid = {}
    
    def add_documents(self, embeddings: np.ndarray, aids: List[str]):
        """Add document embeddings to index"""
        faiss.normalize_L2(embeddings)
        self.index.add(embeddings)
        
        # Map index positions to AIDs
        start_idx = len(self.index_to_aid)
        for i, aid in enumerate(aids):
            self.index_to_aid[start_idx + i] = aid
```

### **Data Flow Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data      â”‚â”€â”€â”€â–¶â”‚  Preprocessing  â”‚â”€â”€â”€â–¶â”‚  Training Data  â”‚
â”‚   (JSON files)  â”‚    â”‚  Pipeline       â”‚    â”‚  (Triplets/Pairs)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Models        â”‚â—€â”€â”€â”€â”‚  Training       â”‚â—€â”€â”€â”€â”‚  Model Config   â”‚
â”‚   (Saved)       â”‚    â”‚  Pipeline       â”‚    â”‚  (Hyperparams)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FAISS Index   â”‚â—€â”€â”€â”€â”‚  Index Building â”‚â—€â”€â”€â”€â”‚  Document       â”‚
â”‚   (Binary)      â”‚    â”‚  Pipeline       â”‚    â”‚  Embeddings     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Request Processing Pipeline:**

#### **1. Input Validation**
```python
def validate_query(query: str) -> bool:
    """Validate input query"""
    if not query or len(query.strip()) == 0:
        return False
    if len(query) > 1000:  # Max length
        return False
    return True
```

#### **2. Retrieval Phase**
```python
def retrieval_phase(query: str, top_k: int = 100) -> Tuple[List[str], List[float]]:
    """Phase 1: Retrieve relevant documents"""
    # 1. Encode query
    query_embedding = bi_encoder.encode([query])
    
    # 2. Search FAISS index
    distances, indices = faiss_index.search(query_embedding, top_k)
    
    # 3. Convert to AIDs
    retrieved_aids = [index_to_aid[i] for i in indices[0]]
    
    return retrieved_aids, distances[0]
```

#### **3. Reranking Phase**
```python
def reranking_phase(query: str, retrieved_aids: List[str]) -> List[Dict]:
    """Phase 2: Rerank retrieved documents"""
    # 1. Get document contents
    documents = [aid_map[aid] for aid in retrieved_aids]
    
    # 2. Create pairs
    pairs = [[query, doc] for doc in documents]
    
    # 3. Score pairs
    scores = cross_encoder.score_pairs(pairs)
    
    # 4. Create results
    results = [
        {
            "aid": aid,
            "content": doc,
            "rerank_score": score
        }
        for aid, doc, score in zip(retrieved_aids, documents, scores)
    ]
    
    return sorted(results, key=lambda x: x["rerank_score"], reverse=True)
```

### **Performance Metrics:**

#### **1. Retrieval Metrics**
- **Precision@K**: Tá»· lá»‡ documents liÃªn quan trong top-K
- **Recall@K**: Tá»· lá»‡ documents liÃªn quan Ä‘Æ°á»£c tÃ¬m tháº¥y
- **F1@K**: Harmonic mean cá»§a Precision vÃ  Recall
- **MRR**: Mean Reciprocal Rank

#### **2. Reranking Metrics**
- **Accuracy**: Äá»™ chÃ­nh xÃ¡c cá»§a binary classification
- **AUC-ROC**: Area under ROC curve
- **Precision-Recall**: Trade-off giá»¯a precision vÃ  recall

#### **3. End-to-End Metrics**
- **Response Time**: Thá»i gian xá»­ lÃ½ tá»« request Ä‘áº¿n response
- **Throughput**: Sá»‘ requests xá»­ lÃ½ Ä‘Æ°á»£c trong 1 giÃ¢y
- **Memory Usage**: LÆ°á»£ng memory sá»­ dá»¥ng

## ğŸš¨ **TROUBLESHOOTING**

Tham kháº£o cÃ¡c lá»—i thÆ°á»ng gáº·p vÃ  cÃ¡ch kháº¯c phá»¥c chi tiáº¿t trong file `QUICK_START.md` hoáº·c `DEPLOYMENT_GUIDE.md`.

## ğŸ“– **TÃ€I LIá»†U THAM KHáº¢O**

### **Papers:**
- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)
- [Cross-Encoders vs. Bi-Encoders for Zero-Shot Classification](https://arxiv.org/abs/2108.08877)
- [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906)

### **Libraries:**
- [Sentence Transformers](https://www.sbert.net/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Transformers](https://huggingface.co/transformers/)
- [PyTorch](https://pytorch.org/)

### **Datasets:**
- [Vietnamese Legal Corpus](https://github.com/lawbot-team/vietnamese-legal-corpus)
- [Legal QA Dataset](https://github.com/lawbot-team/legal-qa-dataset)

## ğŸ¤ **ÄÃ“NG GÃ“P**

ChÃºng tÃ´i ráº¥t hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p! Vui lÃ²ng Ä‘á»c `CONTRIBUTING.md` Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ“„ **LICENSE**

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c cáº¥p phÃ©p theo MIT License.

---

**Made with â¤ï¸ by LawBot Team**
