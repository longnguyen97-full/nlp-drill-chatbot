# ğŸ—ï¸ SYSTEM ARCHITECTURE - LawBot

> **HÆ°á»›ng dáº«n chi tiáº¿t vá» kiáº¿n trÃºc há»‡ thá»‘ng**  
> Giáº£i thÃ­ch tá»«ng component, luá»“ng dá»¯ liá»‡u vÃ  tÆ°Æ¡ng tÃ¡c

## ğŸ“‹ **Tá»”NG QUAN KIáº¾N TRÃšC**

### **Kiáº¿n trÃºc tá»•ng thá»ƒ:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE LAYER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Web UI    â”‚  â”‚   API REST  â”‚  â”‚  CLI Tools  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APPLICATION LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Pipeline  â”‚  â”‚   Cache     â”‚  â”‚  Monitoring â”‚          â”‚
â”‚  â”‚  Manager    â”‚  â”‚  Manager    â”‚  â”‚   System    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CORE AI LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Bi-Encoder  â”‚  â”‚Cross-Encoderâ”‚  â”‚   FAISS     â”‚          â”‚
â”‚  â”‚ (Retrieval) â”‚  â”‚(Reranking)  â”‚  â”‚   Index     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Raw Data  â”‚  â”‚ Processed   â”‚  â”‚   Models    â”‚          â”‚
â”‚  â”‚   Storage   â”‚  â”‚   Data      â”‚  â”‚   Storage   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” **RETRIEVAL LAYER (BI-ENCODER)**

### **Chá»©c nÄƒng:**
- **Input**: CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
- **Output**: 100 vÄƒn báº£n phÃ¡p luáº­t liÃªn quan nháº¥t
- **Thá»i gian**: 50-100ms

### **Kiáº¿n trÃºc chi tiáº¿t:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input Query   â”‚â”€â”€â”€â–¶â”‚  Bi-Encoder     â”‚â”€â”€â”€â–¶â”‚  Query Vector   â”‚
â”‚   (Text)        â”‚    â”‚  Model          â”‚    â”‚  (768 dim)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retrieved      â”‚â—€â”€â”€â”€â”‚  FAISS Index    â”‚â—€â”€â”€â”€â”‚  Similarity     â”‚
â”‚  Documents      â”‚    â”‚  Search         â”‚    â”‚  Search         â”‚
â”‚  (100 docs)     â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Components:**

#### **1. Bi-Encoder Model:**
```python
# Model: bkai-foundation-models/vietnamese-bi-encoder
# Architecture: Sentence Transformer
# Output dimension: 768
# Training: Multiple Negatives Ranking Loss
```

#### **2. FAISS Index:**
```python
# Index type: IndexFlatIP (Inner Product)
# Normalization: L2 normalization
# Search method: Exact search
# Index size: ~100MB for 100K documents
```

#### **3. Document Embeddings:**
```python
# Pre-computed embeddings for all legal documents
# Storage: FAISS index + metadata mapping
# Update frequency: Batch updates
```

### **Luá»“ng xá»­ lÃ½:**
1. **Tokenization**: Chuyá»ƒn cÃ¢u há»i thÃ nh tokens
2. **Encoding**: Táº¡o embedding vector (768 dim)
3. **Normalization**: L2 normalize vector
4. **Search**: TÃ¬m kiáº¿m trong FAISS index
5. **Ranking**: Sáº¯p xáº¿p theo similarity score
6. **Output**: Tráº£ vá» top 100 documents

## âš–ï¸ **RERANKING LAYER (CROSS-ENCODER)**

### **Chá»©c nÄƒng:**
- **Input**: CÃ¢u há»i + 100 documents tá»« retrieval
- **Output**: Top 5 documents vá»›i Ä‘iá»ƒm sá»‘ chÃ­nh xÃ¡c
- **Thá»i gian**: 200-500ms

### **Kiáº¿n trÃºc chi tiáº¿t:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query + Docs   â”‚â”€â”€â”€â–¶â”‚ Cross-Encoder   â”‚â”€â”€â”€â–¶â”‚  Relevance      â”‚
â”‚  (100 pairs)    â”‚    â”‚  Model          â”‚    â”‚  Scores         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Final Results  â”‚â—€â”€â”€â”€â”‚  Score Ranking  â”‚â—€â”€â”€â”€â”‚  Softmax        â”‚
â”‚  (Top 5)        â”‚    â”‚  & Sorting      â”‚    â”‚  Probabilities  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Components:**

#### **1. Cross-Encoder Model:**
```python
# Model: vinai/phobert-large
# Architecture: RoBERTa-based
# Input: [CLS] query [SEP] document [SEP]
# Output: Binary classification (relevant/not relevant)
```

#### **2. Text Processing:**
```python
# Chunking: Split long documents into chunks
# Overlap: 50 tokens between chunks
# Max length: 256 tokens per chunk
# Strategy: Take max score across chunks
```

#### **3. Batch Processing:**
```python
# Batch size: 4 (configurable)
# Memory optimization: Gradient accumulation
# Device: GPU with mixed precision (FP16)
```

### **Luá»“ng xá»­ lÃ½:**
1. **Pair Creation**: Táº¡o cáº·p (query, document)
2. **Chunking**: Chia documents dÃ i thÃ nh chunks
3. **Tokenization**: Tokenize tá»«ng cáº·p
4. **Batch Processing**: Xá»­ lÃ½ theo batch
5. **Scoring**: TÃ­nh relevance score
6. **Aggregation**: Láº¥y max score cho má»—i document
7. **Ranking**: Sáº¯p xáº¿p theo score
8. **Output**: Tráº£ vá» top 5

## ğŸ“Š **DATA FLOW**

### **Training Data Flow:**
```
Raw Data (legal_corpus.json, train.json)
    â”‚
    â–¼
Preprocessing (03_preprocess_data.py)
    â”‚
    â–¼
Data Splitting (04_split_data.py)
    â”‚
    â–¼
Training Data Preparation (06_prepare_training_data.py)
    â”‚
    â–¼
Data Augmentation (08_augment_data.py)
    â”‚
    â–¼
Model Training (09_train_bi_encoder.py, 11_train_cross_encoder.py)
```

### **Inference Data Flow:**
```
User Query
    â”‚
    â–¼
Bi-Encoder Retrieval
    â”‚
    â–¼
Top 100 Documents
    â”‚
    â–¼
Cross-Encoder Reranking
    â”‚
    â–¼
Top 5 Results
    â”‚
    â–¼
Formatted Response
```

## ğŸ”§ **CONFIGURATION SYSTEM**

### **Environment Variables:**
```bash
# Core settings
LAWBOT_ENV=production
LAWBOT_DEBUG=false

# Paths
LAWBOT_DATA_DIR=/opt/lawbot/data
LAWBOT_MODELS_DIR=/opt/lawbot/models
LAWBOT_INDEXES_DIR=/opt/lawbot/indexes

# Performance
LAWBOT_BI_ENCODER_BATCH_SIZE=8
LAWBOT_CROSS_ENCODER_BATCH_SIZE=4
LAWBOT_TOP_K_RETRIEVAL=100
LAWBOT_TOP_K_FINAL=5

# GPU settings
LAWBOT_FP16_TRAINING=true
CUDA_VISIBLE_DEVICES=0
```

### **Configuration Validation:**
```python
# Auto-validation on import
config.validate_config()
config.print_config_summary()
```

## ğŸ“ **FILE STRUCTURE**

### **Core Components:**
```
core/
â”œâ”€â”€ logging_utils.py      # Unified logging system
â”œâ”€â”€ data_utils.py         # Data processing utilities
â”œâ”€â”€ model_utils.py        # Model loading and inference
â”œâ”€â”€ evaluation_utils.py   # Performance metrics
â””â”€â”€ pipeline_utils.py     # Pipeline orchestration
```

### **Pipeline Scripts:**
```
scripts/
â”œâ”€â”€ 01_check_environment.py      # Environment validation
â”œâ”€â”€ 02_filter_dataset.py         # Data quality filtering
â”œâ”€â”€ 03_preprocess_data.py        # Data preprocessing
â”œâ”€â”€ 04_split_data.py            # Train/validation split
â”œâ”€â”€ 05_validate_mapping.py      # Mapping validation
â”œâ”€â”€ 06_prepare_training_data.py # Training data preparation
â”œâ”€â”€ 07_merge_data.py           # Data merging
â”œâ”€â”€ 08_augment_data.py         # Data augmentation
â”œâ”€â”€ 09_train_bi_encoder.py     # Bi-Encoder training
â”œâ”€â”€ 10_build_faiss_index.py    # FAISS index building
â”œâ”€â”€ 11_train_cross_encoder.py  # Cross-Encoder training
â””â”€â”€ 12_evaluate_pipeline.py    # Pipeline evaluation
```

### **Data Storage:**
```
data/
â”œâ”€â”€ raw/                    # Original data files
â”‚   â”œâ”€â”€ legal_corpus.json  # Legal documents corpus
â”‚   â””â”€â”€ train.json         # Training data
â”œâ”€â”€ processed/              # Processed data files
â”‚   â”œâ”€â”€ aid_map.pkl        # Article ID mapping
â”‚   â”œâ”€â”€ train_triplets_*.jsonl  # Training triplets
â”‚   â””â”€â”€ train_pairs_*.jsonl     # Training pairs
â””â”€â”€ validation/             # Validation data
```

### **Model Storage:**
```
models/
â”œâ”€â”€ bi-encoder/            # Bi-Encoder model files
â”‚   â”œâ”€â”€ config.json        # Model configuration
â”‚   â”œâ”€â”€ pytorch_model.bin  # Model weights
â”‚   â””â”€â”€ tokenizer.json     # Tokenizer files
â””â”€â”€ cross-encoder-v2/      # Cross-Encoder model files
    â”œâ”€â”€ config.json        # Model configuration
    â”œâ”€â”€ pytorch_model.bin  # Model weights
    â””â”€â”€ tokenizer.json     # Tokenizer files
```

### **Index Storage:**
```
indexes/
â”œâ”€â”€ legal.faiss            # FAISS index file
â””â”€â”€ index_to_aid.json     # Index to Article ID mapping
```

## ğŸ”„ **PIPELINE ORCHESTRATION**

### **Main Pipeline Runner:**
```python
# run_pipeline.py
class LegalQAPipeline:
    def __init__(self):
        self.pipeline_steps = self._define_pipeline_steps()
        self.progress_tracker = ProgressTracker()
    
    def run_pipeline(self, start_step=None):
        # Execute pipeline steps sequentially
        # Handle errors and logging
        # Generate progress reports
```

### **Step Execution:**
```python
def run_step(self, step):
    # 1. Validate step configuration
    # 2. Execute subprocess
    # 3. Monitor output
    # 4. Handle errors
    # 5. Update progress
```

### **Error Handling:**
```python
# Comprehensive error handling
try:
    # Execute step
    result = subprocess.run(cmd, capture_output=True)
    if result.returncode != 0:
        raise StepExecutionError(result.stderr)
except Exception as e:
    # Log error
    # Update progress
    # Continue or stop based on step importance
```

## ğŸ“ˆ **PERFORMANCE MONITORING**

### **Metrics Tracking:**
```python
# Performance metrics
metrics = {
    'retrieval_time': 50-100ms,
    'reranking_time': 200-500ms,
    'total_response_time': 250-600ms,
    'memory_usage': '2-4GB',
    'gpu_utilization': '60-80%'
}
```

### **Logging System:**
```python
# Unified logging
logger = get_logger(__name__)
logger.info("Processing query: %s", query)
logger.error("Error in retrieval: %s", error)
logger.debug("Retrieval scores: %s", scores)
```

### **Health Checks:**
```python
# System health monitoring
def health_check():
    # Check model availability
    # Check index integrity
    # Check memory usage
    # Check GPU status
    return health_status
```

## ğŸš€ **DEPLOYMENT ARCHITECTURE**

### **Development Environment:**
```
Local Machine
â”œâ”€â”€ Python Environment
â”œâ”€â”€ GPU Support (optional)
â”œâ”€â”€ Local Data Storage
â””â”€â”€ Development Tools
```

### **Production Environment:**
```
Load Balancer
â”œâ”€â”€ Web Server 1
â”œâ”€â”€ Web Server 2
â””â”€â”€ Web Server 3
    â”œâ”€â”€ LawBot Application
    â”œâ”€â”€ Model Cache
    â””â”€â”€ Request Queue
```

### **Docker Deployment:**
```dockerfile
# Multi-stage build
FROM python:3.9-slim as builder
# Install dependencies

FROM python:3.9-slim as runtime
# Copy application
# Set environment variables
# Expose port
```

## ğŸ”’ **SECURITY CONSIDERATIONS**

### **Data Security:**
- âœ… **Encryption**: Sensitive data encryption
- âœ… **Access Control**: Role-based access
- âœ… **Audit Logging**: Comprehensive logging
- âœ… **Data Privacy**: GDPR compliance

### **System Security:**
- âœ… **Input Validation**: Query sanitization
- âœ… **Rate Limiting**: Request throttling
- âœ… **Authentication**: API key management
- âœ… **HTTPS**: Secure communication

## ğŸ“Š **SCALABILITY**

### **Horizontal Scaling:**
```
Multiple Instances
â”œâ”€â”€ Shared Model Cache
â”œâ”€â”€ Load Balancer
â””â”€â”€ Database Cluster
```

### **Vertical Scaling:**
```
Single Instance
â”œâ”€â”€ More GPU Memory
â”œâ”€â”€ More CPU Cores
â””â”€â”€ More RAM
```

### **Caching Strategy:**
```python
# Multi-level caching
cache = {
    'query_cache': LRU(1000),      # Query results
    'model_cache': LRU(10),         # Model instances
    'index_cache': LRU(1),          # FAISS index
}
```

---

**ğŸ¯ Kiáº¿n trÃºc nÃ y Ä‘áº£m báº£o hiá»‡u suáº¥t cao, kháº£ nÄƒng má»Ÿ rá»™ng vÃ  dá»… báº£o trÃ¬!** 