# ğŸ›ï¸ LawBot - Legal QA Pipeline v8.0 (State-of-the-Art)

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-8.0-green.svg)](https://github.com/lawbot-team/lawbot)
[![Pipeline](https://img.shields.io/badge/pipeline-cascaded--reranking-orange.svg)](https://github.com/lawbot-team/lawbot)

> **Há»‡ thá»‘ng há»i-Ä‘Ã¡p phÃ¡p luáº­t thÃ´ng minh cho Viá»‡t Nam**  
> **PhiÃªn báº£n v8.0: Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t vÃ  cáº¥u trÃºc code**  
> TÃ­ch há»£p cÃ¡c ká»¹ thuáº­t AI tiÃªn tiáº¿n nháº¥t vÃ  tá»‘i Æ°u hÃ³a toÃ n diá»‡n

## âœ¨ **TÃNH NÄ‚NG Ná»”I Báº¬T (KEY FEATURES)**

PhiÃªn báº£n v8.0 tÃ­ch há»£p cÃ¡c ká»¹ thuáº­t hÃ ng Ä‘áº§u vÃ  tá»‘i Æ°u hÃ³a toÃ n diá»‡n:

- **Kiáº¿n trÃºc Xáº¿p háº¡ng Äa táº§ng (Cascaded Reranking)**: Má»™t "phá»…u lá»c" 3 táº§ng thÃ´ng minh giÃºp cÃ¢n báº±ng hoÃ n háº£o giá»¯a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c, cho phÃ©p há»‡ thá»‘ng xá»­ lÃ½ hiá»‡u quáº£ má»™t lÆ°á»£ng lá»›n thÃ´ng tin.

- **Domain-Adaptive Pre-training (DAPT)**: Kháº£ nÄƒng "chuyÃªn mÃ´n hÃ³a" model ngÃ´n ngá»¯, biáº¿n PhoBERT tá»« má»™t chuyÃªn gia Ä‘a ngÃ nh thÃ nh má»™t chuyÃªn gia am hiá»ƒu sÃ¢u sáº¯c vá» phÃ¡p luáº­t (PhoBERT-Law).

- **Há»™i Ä‘á»“ng ChuyÃªn gia (Ensemble Reranking)**: Sá»­ dá»¥ng nhiá»u model Cross-Encoder cÃ¹ng tháº©m Ä‘á»‹nh káº¿t quáº£, giÃºp tÄƒng cÆ°á»ng sá»± á»•n Ä‘á»‹nh vÃ  Ä‘á»™ tin cáº­y cho cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng.

- **Khai thÃ¡c Hard Negatives Tá»± Ä‘á»™ng**: Tá»± Ä‘á»™ng "Ä‘Ã o" ra nhá»¯ng vÃ­ dá»¥ há»c khÃ³ nháº¥t, buá»™c AI pháº£i há»c cÃ¡ch phÃ¢n biá»‡t nhá»¯ng khÃ¡c biá»‡t ngá»¯ nghÄ©a tinh vi trong vÄƒn báº£n luáº­t.

- **Tá»‘i Æ°u hÃ³a Hiá»‡u suáº¥t Váº­n hÃ nh**: 
  - **Mixed Precision Training (FP16)**: TÄƒng tá»‘c Ä‘á»™ huáº¥n luyá»‡n 1.5-2x vÃ  giáº£m 50% VRAM sá»­ dá»¥ng
  - **DataLoader Optimization**: Tá»‘i Æ°u hÃ³a `num_workers`, `pin_memory`, `prefetch_factor` cho hiá»‡u suáº¥t cao nháº¥t
  - **Gradient Accumulation**: MÃ´ phá»ng batch size lá»›n hÆ¡n mÃ  khÃ´ng tÄƒng VRAM

- **Cáº¥u trÃºc Code Tá»‘i Æ°u**: 
  - **Unified Utils Package**: Tá»• chá»©c láº¡i thÃ nh `core/utils/` vá»›i cÃ¡c module chuyÃªn biá»‡t
  - **Centralized Configuration**: Táº¥t cáº£ "magic numbers" Ä‘Æ°á»£c chuyá»ƒn vÃ o `config.py`
  - **Clean Naming**: Loáº¡i bá» trÃ¹ng láº·p vÃ  Ä‘áº·t tÃªn rÃµ rÃ ng hÆ¡n

- **Pipeline Tá»‘i Æ°u & Bá»n bá»‰**: ToÃ n bá»™ quy trÃ¬nh Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i thÃ nh cÃ¡c bÆ°á»›c logic, dá»… quáº£n lÃ½, Ä‘i kÃ¨m há»‡ thá»‘ng logging, giÃ¡m sÃ¡t tiáº¿n Ä‘á»™ vÃ  kiá»ƒm tra cháº¥t lÆ°á»£ng chuyÃªn nghiá»‡p.

## ğŸ“‹ **Tá»”NG QUAN Há»† THá»NG**

### **LawBot lÃ  gÃ¬?**
LawBot lÃ  má»™t há»‡ thá»‘ng há»i-Ä‘Ã¡p phÃ¡p luáº­t tiÃªn tiáº¿n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho phÃ¡p luáº­t Viá»‡t Nam. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ´ng nghá»‡ AI hiá»‡n Ä‘áº¡i Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» phÃ¡p luáº­t má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  nhanh chÃ³ng.

### **Kiáº¿n trÃºc há»‡ thá»‘ng v7.0 (Cascaded Reranking):**
```
            [CÃ¢u há»i ngÆ°á»i dÃ¹ng]
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Táº§ng 1: Bi-Encoder (Retrieval)            â”‚
â”‚  - TÃ¬m kiáº¿m siÃªu rá»™ng, láº¥y Top 500 á»©ng viÃªn â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Táº§ng 2: Light Reranker (Light Reranking) â”‚
â”‚  - SÃ ng lá»c siÃªu nhanh, chá»n Top 50        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Táº§ng 3: Ensemble Reranker (Strong Reranking)â”‚
â”‚  - Há»™i Ä‘á»“ng chuyÃªn gia tháº©m Ä‘á»‹nh sÃ¢u       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            [Top 5 káº¿t quáº£ chÃ­nh xÃ¡c nháº¥t]
```

### **CÃ¡ch hoáº¡t Ä‘á»™ng:**
1. **ğŸ” Táº§ng 1 (Bi-Encoder)**: TÃ¬m 500 vÄƒn báº£n phÃ¡p luáº­t liÃªn quan nháº¥t
2. **âš¡ Táº§ng 2 (Light Reranker)**: Lá»c nhanh xuá»‘ng 50 á»©ng viÃªn cháº¥t lÆ°á»£ng cao
3. **âš–ï¸ Táº§ng 3 (Ensemble)**: Há»™i Ä‘á»“ng chuyÃªn gia tháº©m Ä‘á»‹nh vÃ  chá»n top 5 káº¿t quáº£ chÃ­nh xÃ¡c nháº¥t

## ğŸ¯ **Táº I SAO Cáº¦N LAW BOT? (WHY)**

### **Váº¥n Ä‘á» hiá»‡n táº¡i:**
- âŒ **KhÃ³ tÃ¬m kiáº¿m**: VÄƒn báº£n phÃ¡p luáº­t ráº¥t nhiá»u vÃ  phá»©c táº¡p
- âŒ **Thá»i gian cháº­m**: TÃ¬m kiáº¿m thá»§ cÃ´ng máº¥t nhiá»u thá»i gian
- âŒ **Thiáº¿u chÃ­nh xÃ¡c**: Káº¿t quáº£ tÃ¬m kiáº¿m khÃ´ng Ä‘Ãºng trá»ng tÃ¢m
- âŒ **KhÃ³ hiá»ƒu**: NgÃ´n ngá»¯ phÃ¡p lÃ½ khÃ³ hiá»ƒu vá»›i ngÆ°á»i khÃ´ng chuyÃªn

### **Giáº£i phÃ¡p LawBot v7.0:**
- âœ… **TÃ¬m kiáº¿m nhanh**: AI tÃ¬m kiáº¿m trong vÃ i giÃ¢y
- âœ… **Káº¿t quáº£ chÃ­nh xÃ¡c**: "Phá»…u lá»c" 3 táº§ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Ä‘a
- âœ… **Dá»… hiá»ƒu**: Tráº£ vá» nhá»¯ng Ä‘iá»u luáº­t liÃªn quan trá»±c tiáº¿p nháº¥t
- âœ… **Tiáº¿t kiá»‡m thá»i gian**: Giáº£m thá»i gian tra cá»©u tá»« vÃ i giá» xuá»‘ng cÃ²n vÃ i giÃ¢y

## â° **KHI NÃ€O Sá»¬ Dá»¤NG? (WHEN)**

### **CÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng:**
- ğŸ” **TÃ¬m kiáº¿m luáº­t**: "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
- ğŸ“‹ **Tra cá»©u quy Ä‘á»‹nh**: "Äiá»u kiá»‡n thÃ nh láº­p doanh nghiá»‡p lÃ  gÃ¬?"
- âš–ï¸ **So sÃ¡nh vÄƒn báº£n**: "Sá»± khÃ¡c biá»‡t giá»¯a Luáº­t Doanh nghiá»‡p cÅ© vÃ  má»›i?"
- ğŸ“ **TÃ¬m Ä‘iá»u khoáº£n**: "Äiá»u 113 Bá»™ luáº­t Lao Ä‘á»™ng quy Ä‘á»‹nh gÃ¬?"

### **Khi nÃ o KHÃ”NG sá»­ dá»¥ng:**
- âŒ CÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n phÃ¡p luáº­t
- âŒ YÃªu cáº§u tÆ° váº¥n phÃ¡p lÃ½ chuyÃªn sÃ¢u
- âŒ Thay tháº¿ hoÃ n toÃ n luáº­t sÆ°

## ğŸ“ **Sá»¬ Dá»¤NG á» ÄÃ‚U? (WHERE)**

### **MÃ´i trÆ°á»ng phÃ¡t triá»ƒn:**
- ğŸ’» **Local Development**: MÃ¡y tÃ­nh cÃ¡ nhÃ¢n
- ğŸ–¥ï¸ **Server**: MÃ¡y chá»§ cÃ´ng ty
- â˜ï¸ **Cloud**: AWS, Google Cloud, Azure
- ğŸ³ **Docker**: Container deployment

### **YÃªu cáº§u há»‡ thá»‘ng:**
```
OS: Windows 10+, Ubuntu 18.04+, macOS 10.14+
RAM: Tá»‘i thiá»ƒu 8GB, khuyáº¿n nghá»‹ 16GB+
Storage: Tá»‘i thiá»ƒu 10GB cho models vÃ  data
GPU: NVIDIA GPU vá»›i CUDA (khuyáº¿n nghá»‹)
Python: 3.8+
```

## ğŸ‘¥ **AI CHO? (WHO)**

### **Äá»‘i tÆ°á»£ng sá»­ dá»¥ng:**
- ğŸ‘¨â€ğŸ’¼ **Luáº­t sÆ°**: Tra cá»©u nhanh vÄƒn báº£n phÃ¡p luáº­t
- ğŸ‘¨â€ğŸ’» **NhÃ  phÃ¡t triá»ƒn**: TÃ­ch há»£p vÃ o á»©ng dá»¥ng phÃ¡p lÃ½
- ğŸ‘¨â€ğŸ“ **Sinh viÃªn luáº­t**: Há»c táº­p vÃ  nghiÃªn cá»©u
- ğŸ‘¨â€ğŸ’¼ **Doanh nghiá»‡p**: TuÃ¢n thá»§ quy Ä‘á»‹nh phÃ¡p luáº­t
- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **CÃ´ng dÃ¢n**: TÃ¬m hiá»ƒu quyá»n vÃ  nghÄ©a vá»¥

### **Äá»‘i tÆ°á»£ng phÃ¡t triá»ƒn:**
- ğŸ‘¨â€ğŸ’» **AI/ML Engineers**: PhÃ¡t triá»ƒn vÃ  tá»‘i Æ°u models
- ğŸ‘¨â€ğŸ’» **Software Engineers**: TÃ­ch há»£p vÃ  deployment
- ğŸ‘¨â€ğŸ’» **Data Scientists**: PhÃ¢n tÃ­ch vÃ  cáº£i thiá»‡n performance
- ğŸ‘¨â€ğŸ’» **DevOps Engineers**: Deployment vÃ  monitoring

## ğŸš€ **HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG (QUICK START)**

### **BÆ°á»›c 1: CÃ i Ä‘áº·t MÃ´i trÆ°á»ng**

```bash
# Clone repository
git clone https://github.com/lawbot-team/lawbot.git
cd lawbot

# Táº¡o mÃ´i trÆ°á»ng áº£o
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate     # Windows

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
pip install -r requirements.txt

# (TÃ¹y chá»n) CÃ i Ä‘áº·t thÃªm dependencies cho development
pip install -r requirements-dev.txt
```

### **BÆ°á»›c 2: Cháº¡y ToÃ n bá»™ Pipeline (Má»™t lá»‡nh duy nháº¥t)**

**ğŸ¯ Lá»‡nh khuyáº¿n nghá»‹ - Hiá»‡u suáº¥t cao nháº¥t:**
```bash
python run_pipeline.py
```

**âš¡ Lá»‡nh nhanh - Bá» qua DAPT:**
```bash
python run_pipeline.py --no-dapt
```

**ğŸ”§ CÃ¡c tÃ¹y chá»n khÃ¡c:**
```bash
# Xem danh sÃ¡ch cÃ¡c bÆ°á»›c
python run_pipeline.py --list-steps

# Cháº¡y tá»« bÆ°á»›c cá»¥ thá»ƒ
python run_pipeline.py --step 02

# Bá» qua bÆ°á»›c filtering
python run_pipeline.py --skip-filtering
```

### **BÆ°á»›c 3: Cháº¡y Giao diá»‡n Web App**

Sau khi pipeline hoÃ n táº¥t, khá»Ÿi Ä‘á»™ng giao diá»‡n ngÆ°á»i dÃ¹ng:

```bash
streamlit run app.py
```

Truy cáº­p http://localhost:8501 Ä‘á»ƒ báº¯t Ä‘áº§u sá»­ dá»¥ng.

### **BÆ°á»›c 4: Sá»­ dá»¥ng API**

```python
from core.pipeline import LegalQAPipeline

# Khá»Ÿi táº¡o pipeline
pipeline = LegalQAPipeline()

# Há»i Ä‘Ã¡p
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
results = pipeline.predict(query=query, top_k_retrieval=100, top_k_final=5)

# In káº¿t quáº£
for i, result in enumerate(results):
    print(f"Káº¿t quáº£ {i+1}: {result['aid']}")
    print(f"Äiá»ƒm: {result['rerank_score']:.4f}")
    print(f"Ná»™i dung: {result['content'][:200]}...")
```





## ğŸ“ **Cáº¤U TRÃšC Dá»° ÃN**

```
LawBot/
â”œâ”€â”€ ğŸ“ app/
â”‚   â””â”€â”€ app.py                  # Giao diá»‡n web Streamlit
â”œâ”€â”€ ğŸ“ core/                    # CÃ¡c module vÃ  class cá»‘t lÃµi
â”‚   â”œâ”€â”€ pipeline.py             # Class pipeline xá»­ lÃ½ chÃ­nh (3 táº§ng)
â”‚   â”œâ”€â”€ logging_system.py       # Há»‡ thá»‘ng ghi log chuyÃªn nghiá»‡p
â”‚   â”œâ”€â”€ evaluation_reporter.py  # CÃ´ng cá»¥ Ä‘Ã¡nh giÃ¡ vÃ  táº¡o bÃ¡o cÃ¡o
â”‚   â”œâ”€â”€ progress_tracker.py     # CÃ´ng cá»¥ theo dÃµi tiáº¿n trÃ¬nh
â”‚   â””â”€â”€ ğŸ“ utils/               # Package utilities thá»‘ng nháº¥t
â”‚       â”œâ”€â”€ __init__.py         # Export táº¥t cáº£ utilities
â”‚       â”œâ”€â”€ data_processing.py  # Xá»­ lÃ½ dá»¯ liá»‡u (load, save, parse)
â”‚       â”œâ”€â”€ model_utils.py      # Utilities cho models (preprocessing, metrics)
â”‚       â”œâ”€â”€ evaluation.py       # Metrics Ä‘Ã¡nh giÃ¡ (precision, recall, MRR)
â”‚       â”œâ”€â”€ augmentation.py     # Data augmentation utilities
â”‚       â””â”€â”€ file_utils.py       # File vÃ  path management
â”œâ”€â”€ ğŸ“ scripts/                 # CÃ¡c ká»‹ch báº£n thá»±c thi pipeline
â”‚   â”œâ”€â”€ 00_adapt_model.py       # (NÃ¢ng cao) Domain-Adaptive Pre-training
â”‚   â”œâ”€â”€ 01_check_environment.py # BÆ°á»›c 1: MÃ´i trÆ°á»ng & SÆ¡ cháº¿
â”‚   â”œâ”€â”€ 02_prepare_training_data.py # BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u training
â”‚   â”œâ”€â”€ 03_train_models.py      # BÆ°á»›c 3: Huáº¥n luyá»‡n & ÄÃ¡nh giÃ¡
â”‚   â””â”€â”€ ğŸ“ utils/               # CÃ¡c script tiá»‡n Ã­ch
â”‚       â”œâ”€â”€ filter_dataset.py   # Logic lá»c dá»¯ liá»‡u
â”‚       â”œâ”€â”€ run_filter.py       # Wrapper Ä‘á»ƒ cháº¡y filter
â”‚       â””â”€â”€ check_project.py    # Kiá»ƒm tra cáº¥u trÃºc dá»± Ã¡n
â”œâ”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“ models/                  # NÆ¡i lÆ°u cÃ¡c model Ä‘Ã£ huáº¥n luyá»‡n
â”‚   â”œâ”€â”€ phobert-law/            # (NÃ¢ng cao) Model chuyÃªn gia phÃ¡p luáº­t
â”‚   â”œâ”€â”€ light-reranker/         # Model reranker siÃªu nhanh
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ“ indexes/                 # NÆ¡i lÆ°u FAISS index
â”œâ”€â”€ ğŸ“ reports/                 # CÃ¡c bÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡
â”œâ”€â”€ ğŸ“ logs/                    # CÃ¡c file log cá»§a má»—i láº§n cháº¡y
â”œâ”€â”€ ğŸ“„ config.py                # File cáº¥u hÃ¬nh trung tÃ¢m (tá»‘i Æ°u hÃ³a)
â”œâ”€â”€ ğŸ“„ run_pipeline.py          # TrÃ¬nh Ä‘iá»u khiá»ƒn pipeline chÃ­nh
â””â”€â”€ ğŸ“„ README.md                # TÃ i liá»‡u hÆ°á»›ng dáº«n
```

## ğŸ› ï¸ **Cáº¤U HÃŒNH & TÃ™Y CHá»ˆNH**

Táº¥t cáº£ cÃ¡c tham sá»‘ quan trá»ng cá»§a há»‡ thá»‘ng Ä‘á»u Ä‘Æ°á»£c quáº£n lÃ½ táº­p trung táº¡i `config.py`. Báº¡n cÃ³ thá»ƒ dá»… dÃ ng thay Ä‘á»•i model, Ä‘iá»u chá»‰nh siÃªu tham sá»‘ huáº¥n luyá»‡n (learning rate, batch size) vÃ  cÃ¡c cÃ i Ä‘áº·t cá»§a pipeline táº¡i Ä‘Ã¢y.

Há»‡ thá»‘ng cÅ©ng há»— trá»£ cáº¥u hÃ¬nh qua **Biáº¿n MÃ´i trÆ°á»ng (Environment Variables)**, ráº¥t há»¯u Ã­ch khi triá»ƒn khai lÃªn server.

### **Environment Variables**

```bash
# Environment
export LAWBOT_ENV=production
export LAWBOT_DEBUG=false

# Directories
export LAWBOT_DATA_DIR=/path/to/data
export LAWBOT_MODELS_DIR=/path/to/models
export LAWBOT_INDEXES_DIR=/path/to/indexes

# Hyperparameters (Tá»‘i Æ°u hÃ³a v8.0)
export LAWBOT_BI_ENCODER_BATCH_SIZE=16      # TÄƒng tá»« 4 lÃªn 16
export LAWBOT_CROSS_ENCODER_BATCH_SIZE=8    # TÄƒng tá»« 4 lÃªn 8
export LAWBOT_BI_ENCODER_LR=2e-5            # TÄƒng tá»« 1e-7 lÃªn 2e-5
export LAWBOT_CROSS_ENCODER_LR=2e-5         # TÄƒng tá»« 5e-6 lÃªn 2e-5
export LAWBOT_BI_ENCODER_EPOCHS=3           # TÄƒng tá»« 1 lÃªn 3
export LAWBOT_CROSS_ENCODER_EPOCHS=5        # TÄƒng tá»« 1 lÃªn 5

# Performance Optimizations (Má»›i v8.0)
export LAWBOT_FP16_TRAINING=true            # Mixed Precision Training
export LAWBOT_BI_ENCODER_DATALOADER_NUM_WORKERS=4
export LAWBOT_CROSS_ENCODER_DATALOADER_NUM_WORKERS=4
export LAWBOT_BI_ENCODER_DATALOADER_PIN_MEMORY=true
export LAWBOT_CROSS_ENCODER_DATALOADER_PIN_MEMORY=true

# Pipeline settings
export LAWBOT_TOP_K_RETRIEVAL=100
export LAWBOT_TOP_K_FINAL=5
```

### **Configuration File**

```python
import config

# In thÃ´ng tin cáº¥u hÃ¬nh
config.print_config_summary()

# Validate cáº¥u hÃ¬nh
config.validate_config()
```

## ğŸ”„ **LUá»’NG Xá»¬ LÃ NGHIá»†P Vá»¤ CHI TIáº¾T**

### **ğŸ¯ Quy trÃ¬nh xá»­ lÃ½ cÃ¢u há»i phÃ¡p luáº­t (Inference Pipeline):**

HÃ£y tÆ°á»Ÿng tÆ°á»£ng LawBot nhÆ° má»™t thÆ° viá»‡n phÃ¡p luáº­t khá»•ng lá»“ cÃ³ hai bá»™ pháº­n chÃ­nh:

#### **1. Bá»™ pháº­n "Tra cá»©u" (Inference/Request)**
ÄÃ¢y lÃ  khi cÃ³ ngÆ°á»i Ä‘áº¿n há»i vÃ  cÃ¡c "thá»§ thÆ° AI" nhanh chÃ³ng tÃ¬m ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c. QuÃ¡ trÃ¬nh nÃ y diá»…n ra má»—i khi ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¢u há»i.

**Bá»‘i cáº£nh**: Báº¡n má»Ÿ trÃ¬nh duyá»‡t, truy cáº­p vÃ o giao diá»‡n web do `app.py` táº¡o ra vÃ  gÃµ cÃ¢u há»i: *"NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"*

**HÃ nh trÃ¬nh chi tiáº¿t**:

* **BÆ°á»›c 1: Giao diá»‡n nháº­n cÃ¢u há»i (`app.py`)**
  * Giao diá»‡n web Ä‘Æ°á»£c táº¡o bá»Ÿi Streamlit trong file `app.py` sáº½ nháº­n cÃ¢u há»i cá»§a báº¡n.
  * Khi báº¡n nháº¥n nÃºt "TÃ¬m kiáº¿m", nÃ³ sáº½ gá»i hÃ m `pipeline.predict()` vÃ  truyá»n cÃ¢u há»i cá»§a báº¡n vÃ o.
  * `pipeline` á»Ÿ Ä‘Ã¢y lÃ  má»™t thá»±c thá»ƒ cá»§a class `LegalQAPipeline` Ä‘Ã£ Ä‘Æ°á»£c táº£i sáºµn.

* **BÆ°á»›c 2: Pipeline báº¯t Ä‘áº§u xá»­ lÃ½ (`core/pipeline.py`)**
  * HÃ m `predict()` trong `LegalQAPipeline` nháº­n nhiá»‡m vá»¥.
  * NÃ³ sáº½ Ä‘iá»u phá»‘i má»™t quy trÃ¬nh "phá»…u lá»c" 3 táº§ng tinh vi cÃ³ tÃªn lÃ  **Cascaded Reranking** Ä‘á»ƒ Ä‘áº£m báº£o káº¿t quáº£ vá»«a nhanh vá»«a chÃ­nh xÃ¡c.

* **BÆ°á»›c 3: Táº§ng 1 - TÃ¬m kiáº¿m Rá»™ng (Retrieval)**
  * **Má»¥c tiÃªu**: Nhanh chÃ³ng tÃ¬m ra khoáº£ng 500 vÄƒn báº£n luáº­t cÃ³ váº» liÃªn quan nháº¥t tá»« toÃ n bá»™ kho dá»¯ liá»‡u.
  * **CÃ¡ch lÃ m**:
    1. HÃ m `retrieve()` Ä‘Æ°á»£c gá»i.
    2. MÃ´ hÃ¬nh `Bi-Encoder` (má»™t chuyÃªn gia tá»‘c Ä‘á»™) sáº½ "Ä‘á»c" cÃ¢u há»i cá»§a báº¡n vÃ  chuyá»ƒn nÃ³ thÃ nh má»™t vector (má»™t chuá»—i sá»‘ Ä‘áº¡i diá»‡n cho Ã½ nghÄ©a).
    3. Vector nÃ y Ä‘Æ°á»£c Ä‘em Ä‘i so sÃ¡nh vá»›i hÃ ng ngÃ n vector cá»§a cÃ¡c vÄƒn báº£n luáº­t Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a vÃ  lÆ°u sáºµn trong má»™t "cuá»‘n sá»• tra cá»©u siÃªu tá»‘c" gá»i lÃ  `FAISS index`.
    4. FAISS index tráº£ vá» 500 vÄƒn báº£n cÃ³ vector gáº§n giá»‘ng vá»›i vector cÃ¢u há»i nháº¥t, cÃ¹ng vá»›i Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng ban Ä‘áº§u.

* **BÆ°á»›c 4: Táº§ng 2 - SÃ ng lá»c Nhanh (Light Reranking)**
  * **Má»¥c tiÃªu**: Giáº£m táº£i cho táº§ng cuá»‘i báº±ng cÃ¡ch lá»c tá»« 500 á»©ng viÃªn xuá»‘ng cÃ²n khoáº£ng 50 á»©ng viÃªn cháº¥t lÆ°á»£ng cao.
  * **CÃ¡ch lÃ m**:
    1. HÃ m `rerank_light()` Ä‘Æ°á»£c gá»i (náº¿u `use_cascaded_reranking` Ä‘Æ°á»£c báº­t).
    2. Má»™t mÃ´ hÃ¬nh nhá» vÃ  nhanh gá»i lÃ  `Light Reranker` sáº½ Ä‘á»c lÆ°á»›t qua cáº·p (cÃ¢u há»i, tá»«ng vÄƒn báº£n trong 500 á»©ng viÃªn) Ä‘á»ƒ cho má»™t Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ sÆ¡ bá»™.
    3. Há»‡ thá»‘ng káº¿t há»£p Ä‘iá»ƒm sÆ¡ bá»™ nÃ y vá»›i Ä‘iá»ƒm tá»« Táº§ng 1 Ä‘á»ƒ ra má»™t Ä‘iá»ƒm tá»•ng há»£p, sau Ä‘Ã³ chá»n ra 50 á»©ng viÃªn cÃ³ Ä‘iá»ƒm cao nháº¥t.

* **BÆ°á»›c 5: Táº§ng 3 - Tháº©m Ä‘á»‹nh ChuyÃªn sÃ¢u (Strong Reranking)**
  * **Má»¥c tiÃªu**: Äáº¡t Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Ä‘a báº±ng cÃ¡ch Ä‘á»ƒ má»™t "há»™i Ä‘á»“ng chuyÃªn gia" tháº©m Ä‘á»‹nh ká»¹ lÆ°á»¡ng 50 á»©ng viÃªn cÃ²n láº¡i.
  * **CÃ¡ch lÃ m**:
    1. HÃ m `rerank()` Ä‘Æ°á»£c gá»i.
    2. **Há»™i Ä‘á»“ng chuyÃªn gia (Ensemble)**: Thay vÃ¬ chá»‰ dÃ¹ng má»™t mÃ´ hÃ¬nh, há»‡ thá»‘ng sá»­ dá»¥ng nhiá»u mÃ´ hÃ¬nh `Cross-Encoder` máº¡nh (vÃ­ dá»¥: `PhoBERT-Law` Ä‘Ã£ Ä‘Æ°á»£c "chuyÃªn mÃ´n hÃ³a" vÃ  má»™t mÃ´ hÃ¬nh khÃ¡c nhÆ° `XLM-RoBERTa`) cÃ¹ng lÃ m viá»‡c.
    3. Tá»«ng chuyÃªn gia trong há»™i Ä‘á»“ng sáº½ Ä‘á»c ráº¥t ká»¹ tá»«ng cáº·p (cÃ¢u há»i, vÄƒn báº£n) vÃ  cho má»™t Ä‘iá»ƒm sá»‘ chi tiáº¿t vá» má»©c Ä‘á»™ liÃªn quan.
    4. **Xá»­ lÃ½ vÄƒn báº£n dÃ i**: Náº¿u má»™t vÄƒn báº£n quÃ¡ dÃ i, há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng cáº¯t nÃ³ thÃ nh cÃ¡c "chunk" (Ä‘oáº¡n) nhá» hÆ¡n Ä‘á»ƒ cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘á»c háº¿t mÃ  khÃ´ng bá» sÃ³t thÃ´ng tin.
    5. Äiá»ƒm sá»‘ cuá»‘i cÃ¹ng cá»§a má»—i vÄƒn báº£n sáº½ lÃ  Ä‘iá»ƒm trung bÃ¬nh tá»« táº¥t cáº£ cÃ¡c chuyÃªn gia (hoáº·c Ä‘iá»ƒm cao nháº¥t tá»« cÃ¡c chunk cá»§a nÃ³).

* **BÆ°á»›c 6: Tráº£ káº¿t quáº£ vá» giao diá»‡n (`app.py`)**
  * HÃ m `predict()` tráº£ vá» danh sÃ¡ch cÃ¡c vÄƒn báº£n Ä‘Ã£ Ä‘Æ°á»£c há»™i Ä‘á»“ng chuyÃªn gia xáº¿p háº¡ng cao nháº¥t.
  * Giao diá»‡n `app.py` nháº­n láº¥y danh sÃ¡ch nÃ y vÃ  hiá»ƒn thá»‹ má»™t cÃ¡ch Ä‘áº¹p Ä‘áº½, dá»… Ä‘á»c cho báº¡n, bao gá»“m ná»™i dung Ä‘iá»u luáº­t vÃ  Ä‘iá»ƒm sá»‘ Ä‘á»ƒ báº¡n biáº¿t má»©c Ä‘á»™ tin cáº­y.

### **ğŸ§  Luá»“ng Logic Huáº¥n luyá»‡n MÃ´ hÃ¬nh (Training Pipeline):**

ÄÃ¢y lÃ  quÃ¡ trÃ¬nh "dáº¡y há»c" cho cÃ¡c AI, diá»…n ra má»™t láº§n trÆ°á»›c khi há»‡ thá»‘ng cÃ³ thá»ƒ sá»­ dá»¥ng. ToÃ n bá»™ quÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn bá»Ÿi file `run_pipeline.py`.

**Bá»‘i cáº£nh**: Báº¡n lÃ  nhÃ  phÃ¡t triá»ƒn, vá»«a táº£i mÃ£ nguá»“n vá» vÃ  cÃ³ trong tay bá»™ dá»¯ liá»‡u thÃ´ (`legal_corpus.json`, `train.json`). Báº¡n má»Ÿ terminal vÃ  chuáº©n bá»‹ cháº¡y.

**HÃ nh trÃ¬nh chi tiáº¿t**:

* **BÆ°á»›c 0 (TÃ¹y chá»n nhÆ°ng quan trá»ng): ChuyÃªn mÃ´n hÃ³a NgÃ´n ngá»¯ (`00_adapt_model.py`)**
  * **Má»¥c tiÃªu**: Biáº¿n mÃ´ hÃ¬nh `PhoBERT` (má»™t chuyÃªn gia ngÃ´n ngá»¯ tá»•ng quÃ¡t) thÃ nh `PhoBERT-Law` (má»™t chuyÃªn gia am hiá»ƒu sÃ¢u vá» thuáº­t ngá»¯ phÃ¡p lÃ½). QuÃ¡ trÃ¬nh nÃ y gá»i lÃ  **Domain-Adaptive Pre-training (DAPT)**.
  * **CÃ¡ch lÃ m**: Script nÃ y cho mÃ´ hÃ¬nh `PhoBERT` Ä‘á»c toÃ n bá»™ kho vÄƒn báº£n luáº­t trong `legal_corpus.json` vÃ  há»c láº¡i cÃ¡ch cÃ¡c tá»« ngá»¯ Ä‘Æ°á»£c sá»­ dá»¥ng trong bá»‘i cáº£nh phÃ¡p luáº­t. Káº¿t quáº£ lÃ  má»™t mÃ´ hÃ¬nh má»›i, "thÃ´ng tháº¡o" luáº­t hÆ¡n, Ä‘Æ°á»£c lÆ°u láº¡i Ä‘á»ƒ cÃ¡c bÆ°á»›c sau sá»­ dá»¥ng.

* **BÆ°á»›c 1: Chuáº©n bá»‹ MÃ´i trÆ°á»ng vÃ  Dá»¯ liá»‡u (`01_check_environment.py`)**
  * **Má»¥c tiÃªu**: Dá»n dáº¹p "sÃ¢n chÆ¡i" vÃ  chuáº©n bá»‹ nguyÃªn liá»‡u.
  * **CÃ¡ch lÃ m**: Script nÃ y kiá»ƒm tra xem báº¡n Ä‘Ã£ cÃ i Ä‘á»§ cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t chÆ°a, cÃ¡c file dá»¯ liá»‡u cÃ³ tá»“n táº¡i khÃ´ng. Quan trá»ng nháº¥t, nÃ³ Ä‘á»c dá»¯ liá»‡u thÃ´ vÃ  táº¡o ra cÃ¡c "báº£n Ä‘á»“" (`aid_map`, `doc_id_to_aids`) Ä‘á»ƒ dá»… dÃ ng tra cá»©u ná»™i dung vÄƒn báº£n tá»« ID cá»§a nÃ³, Ä‘á»“ng thá»i chia dá»¯ liá»‡u ra thÃ nh 2 táº­p: má»™t Ä‘á»ƒ huáº¥n luyá»‡n (train), má»™t Ä‘á»ƒ kiá»ƒm tra (validation).

* **BÆ°á»›c 2: Chuáº©n bá»‹ Dá»¯ liá»‡u Huáº¥n luyá»‡n NÃ¢ng cao (`02_prepare_training_data.py`)**
  * **Má»¥c tiÃªu**: Táº¡o ra "bÃ i táº­p" cháº¥t lÆ°á»£ng cao Ä‘á»ƒ dáº¡y cho cÃ¡c mÃ´ hÃ¬nh AI.
  * **CÃ¡ch lÃ m**: ÄÃ¢y lÃ  má»™t bÆ°á»›c cá»±c ká»³ thÃ´ng minh.
    1. **Táº¡o "bÃ i táº­p dá»…"**: Äáº§u tiÃªn, nÃ³ táº¡o ra cÃ¡c bá»™ ba (cÃ¢u há»i, cÃ¢u tráº£ lá»i Ä‘Ãºng, cÃ¢u tráº£ lá»i sai ngáº«u nhiÃªn). ÄÃ¢y lÃ  nhá»¯ng bÃ i táº­p cÆ¡ báº£n.
    2. **ÄÃ o táº¡o "giÃ¡o viÃªn táº¡m thá»i"**: NÃ³ dÃ¹ng nhá»¯ng bÃ i táº­p dá»… nÃ y Ä‘á»ƒ huáº¥n luyá»‡n nhanh má»™t mÃ´ hÃ¬nh `Bi-Encoder` táº¡m thá»i.
    3. **TÃ¬m "bÃ i táº­p khÃ³" (Hard Negative Mining)**: NÃ³ dÃ¹ng "giÃ¡o viÃªn táº¡m thá»i" nÃ y Ä‘á»ƒ tÃ¬m kiáº¿m cÃ¡c cÃ¢u tráº£ lá»i *sai* nhÆ°ng láº¡i cÃ³ váº» *ráº¥t giá»‘ng* vá»›i cÃ¢u tráº£ lá»i Ä‘Ãºng. ÄÃ¢y chÃ­nh lÃ  cÃ¡c "báº«y" ngá»¯ nghÄ©a mÃ  AI cáº§n pháº£i há»c Ä‘á»ƒ vÆ°á»£t qua.
    4. **Táº¡o bá»™ bÃ i táº­p cuá»‘i cÃ¹ng**: NÃ³ káº¿t há»£p cáº£ "bÃ i táº­p dá»…" vÃ  "bÃ i táº­p khÃ³" Ä‘á»ƒ táº¡o ra bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n cuá»‘i cÃ¹ng, giÃºp AI trá»Ÿ nÃªn thÃ´ng minh vÃ  tinh vi hÆ¡n. Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c lÆ°u láº¡i cho cáº£ `Bi-Encoder` (dáº¡ng triplets) vÃ  `Cross-Encoder` (dáº¡ng pairs).

* **BÆ°á»›c 3: Huáº¥n luyá»‡n vÃ  ÄÃ¡nh giÃ¡ (`03_train_models.py`)**
  * **Má»¥c tiÃªu**: DÃ¹ng bá»™ "bÃ i táº­p" cháº¥t lÆ°á»£ng cao Ä‘á»ƒ huáº¥n luyá»‡n táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh chÃ­nh thá»©c.
  * **CÃ¡ch lÃ m**:
    1. **Huáº¥n luyá»‡n Bi-Encoder**: Dáº¡y cho "chuyÃªn gia tá»‘c Ä‘á»™" cÃ¡ch phÃ¢n biá»‡t cÃ¢u tráº£ lá»i Ä‘Ãºng vÃ  sai tá»« cÃ¡c bÃ i táº­p triplets Ä‘Ã£ táº¡o.
    2. **XÃ¢y dá»±ng FAISS Index**: DÃ¹ng `Bi-Encoder` vá»«a Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ táº¡o vector cho táº¥t cáº£ vÄƒn báº£n luáº­t vÃ  xÃ¢y dá»±ng nÃªn "cuá»‘n sá»• tra cá»©u siÃªu tá»‘c" FAISS.
    3. **Huáº¥n luyá»‡n Light Reranker**: Dáº¡y cho "ngÆ°á»i sÃ ng lá»c nhanh" cÃ¡ch Ä‘Ã¡nh giÃ¡ sÆ¡ bá»™.
    4. **Huáº¥n luyá»‡n Cross-Encoder (Há»™i Ä‘á»“ng chuyÃªn gia)**: Dáº¡y cho cÃ¡c "chuyÃªn gia tháº©m Ä‘á»‹nh" cÃ¡ch phÃ¢n tÃ­ch sÃ¢u. Náº¿u `PhoBERT-Law` tá»« BÆ°á»›c 0 tá»“n táº¡i, nÃ³ sáº½ Ä‘Æ°á»£c dÃ¹ng lÃ m ná»n táº£ng Ä‘á»ƒ huáº¥n luyá»‡n, táº¡o ra má»™t chuyÃªn gia cá»±c ká»³ sáº¯c bÃ©n.
    5. **ÄÃ¡nh giÃ¡**: Sau khi huáº¥n luyá»‡n, script sáº½ tá»± Ä‘á»™ng cháº¡y cÃ¡c bÃ i kiá»ƒm tra (sá»­ dá»¥ng `evaluation_utils.py`) Ä‘á»ƒ bÃ¡o cÃ¡o xem cÃ¡c mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t Ä‘áº¿n Ä‘Ã¢u.

## ğŸš€ **HÆ¯á»šNG DáºªN Báº®T Äáº¦U NHANH (QUICK START GUIDE)**

### **CÃ¡ch Cháº¡y Project Láº§n Ä‘áº§u Hiá»‡u quáº£**

Äá»ƒ khá»Ÿi Ä‘á»™ng dá»± Ã¡n nÃ y, báº¡n chá»‰ cáº§n lÃ m theo cÃ¡c bÆ°á»›c Ä‘Æ¡n giáº£n sau:

#### **BÆ°á»›c 1: Chuáº©n bá»‹ MÃ´i trÆ°á»ng**
* Táº£i mÃ£ nguá»“n vá» mÃ¡y: `git clone https://github.com/lawbot-team/lawbot.git`
* Äi vÃ o thÆ° má»¥c dá»± Ã¡n: `cd lawbot`
* Táº¡o má»™t mÃ´i trÆ°á»ng áº£o Ä‘á»ƒ khÃ´ng lÃ m áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c thÆ° viá»‡n Python khÃ¡c trÃªn mÃ¡y cá»§a báº¡n: `python -m venv venv`
* KÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o:
  * TrÃªn Windows: `venv\Scripts\activate`
  * TrÃªn Linux/Mac: `source venv/bin/activate`
* CÃ i Ä‘áº·t táº¥t cáº£ cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t chá»‰ báº±ng má»™t lá»‡nh: `pip install -r requirements.txt`

#### **BÆ°á»›c 2: Chuáº©n bá»‹ Dá»¯ liá»‡u**
* HÃ£y cháº¯c cháº¯n ráº±ng báº¡n cÃ³ cÃ¡c file dá»¯ liá»‡u thÃ´ (`legal_corpus.json`, `train.json`, `public_test.json`).
* Äáº·t chÃºng vÃ o Ä‘Ãºng vá»‹ trÃ­: thÆ° má»¥c `data/raw/`. Cáº¥u trÃºc thÆ° má»¥c nÃ y Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong file `config.py`.

#### **BÆ°á»›c 3: Cháº¡y ToÃ n bá»™ Pipeline Huáº¥n luyá»‡n**
* BÃ¢y giá» lÃ  pháº§n thÃº vá»‹ nháº¥t. Báº¡n chá»‰ cáº§n cháº¡y má»™t lá»‡nh duy nháº¥t trong terminal:
```bash
python run_pipeline.py
```
* Lá»‡nh nÃ y sáº½ tá»± Ä‘á»™ng thá»±c hiá»‡n táº¥t cáº£ cÃ¡c bÆ°á»›c huáº¥n luyá»‡n tá»« 0 Ä‘áº¿n 3 mÃ  tÃ´i Ä‘Ã£ giáº£i thÃ­ch á»Ÿ trÃªn. NÃ³ sáº½ tá»± Ä‘á»™ng chuyÃªn mÃ´n hÃ³a mÃ´ hÃ¬nh, chuáº©n bá»‹ dá»¯ liá»‡u, tÃ¬m hard negatives, vÃ  huáº¥n luyá»‡n táº¥t cáº£ cÃ¡c AI. QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t khÃ¡ nhiá»u thá»i gian (vÃ i giá») tÃ¹y thuá»™c vÃ o sá»©c máº¡nh mÃ¡y tÃ­nh cá»§a báº¡n, Ä‘áº·c biá»‡t lÃ  á»Ÿ bÆ°á»›c 0 (DAPT) vÃ  bÆ°á»›c 3 (Training).

* **Máº¹o Ä‘á»ƒ cháº¡y nhanh hÆ¡n láº§n Ä‘áº§u**: Náº¿u báº¡n muá»‘n tháº¥y káº¿t quáº£ nhanh hÆ¡n, báº¡n cÃ³ thá»ƒ bá» qua bÆ°á»›c DAPT (BÆ°á»›c 0) tá»‘n nhiá»u thá»i gian báº±ng lá»‡nh:
```bash
python run_pipeline.py --no-dapt
```
Há»‡ thá»‘ng váº«n sáº½ hoáº¡t Ä‘á»™ng tá»‘t, chá»‰ lÃ  Ä‘á»™ chÃ­nh xÃ¡c cÃ³ thá»ƒ khÃ´ng á»Ÿ má»©c tá»‘i Ä‘a.

#### **BÆ°á»›c 4: Khá»Ÿi Ä‘á»™ng Giao diá»‡n Web**
* Sau khi pipeline á»Ÿ BÆ°á»›c 3 cháº¡y xong vÃ  bÃ¡o thÃ nh cÃ´ng, táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh AI cá»§a báº¡n Ä‘Ã£ sáºµn sÃ ng.
* Cháº¡y lá»‡nh sau Ä‘á»ƒ khá»Ÿi Ä‘á»™ng giao diá»‡n web:
```bash
streamlit run app.py
```
* Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p vÃ o Ä‘á»‹a chá»‰ `http://localhost:8501`. BÃ¢y giá» báº¡n cÃ³ thá»ƒ trá»±c tiáº¿p Ä‘áº·t cÃ¢u há»i vÃ  chiÃªm ngÆ°á»¡ng thÃ nh quáº£ cá»§a mÃ¬nh!

### **CÃ¡c TÃ¹y chá»n Cháº¡y KhÃ¡c**

#### **Cháº¡y tá»«ng bÆ°á»›c riÃªng láº»:**
```bash
# BÆ°á»›c 0: DAPT (Domain-Adaptive Pre-training)
python scripts/00_adapt_model.py

# BÆ°á»›c 1: Kiá»ƒm tra mÃ´i trÆ°á»ng vÃ  xá»­ lÃ½ dá»¯ liá»‡u
python scripts/01_check_environment.py

# BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u training
python scripts/02_prepare_training_data.py

# BÆ°á»›c 3: Huáº¥n luyá»‡n models vÃ  Ä‘Ã¡nh giÃ¡
python scripts/03_train_models.py
```

#### **CÃ¡c tÃ¹y chá»n khÃ¡c:**
```bash
# Xem danh sÃ¡ch cÃ¡c bÆ°á»›c
python run_pipeline.py --list-steps

# Cháº¡y tá»« bÆ°á»›c cá»¥ thá»ƒ
python run_pipeline.py --step 02

# Bá» qua bÆ°á»›c filtering
python run_pipeline.py --skip-filtering
```

## ğŸ”„ **LUá»’NG Xá»¬ LÃ NGHIá»†P Vá»¤ CHI TIáº¾T**

### **ğŸ¯ Quy trÃ¬nh xá»­ lÃ½ cÃ¢u há»i phÃ¡p luáº­t:**

#### **1. Tiáº¿p nháº­n cÃ¢u há»i**
- **Input**: NgÆ°á»i dÃ¹ng nháº­p cÃ¢u há»i vá» phÃ¡p luáº­t
- **VÃ­ dá»¥**: "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
- **Xá»­ lÃ½**: Há»‡ thá»‘ng phÃ¢n tÃ­ch vÃ  chuáº©n hÃ³a cÃ¢u há»i

#### **2. Táº§ng 1: TÃ¬m kiáº¿m rá»™ng (Bi-Encoder)**
- **Má»¥c Ä‘Ã­ch**: TÃ¬m 500 vÄƒn báº£n phÃ¡p luáº­t cÃ³ liÃªn quan nháº¥t
- **CÃ¡ch hoáº¡t Ä‘á»™ng**: 
  - Chuyá»ƒn cÃ¢u há»i thÃ nh vector 768 chiá»u
  - So sÃ¡nh vá»›i táº¥t cáº£ vÄƒn báº£n trong kho dá»¯ liá»‡u
  - Tráº£ vá» 500 káº¿t quáº£ cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao nháº¥t
- **Thá»i gian**: ~100ms
- **Äá»™ chÃ­nh xÃ¡c**: ~70% (Precision@5)

#### **3. Táº§ng 2: Lá»c nhanh (Light Reranker)**
- **Má»¥c Ä‘Ã­ch**: Lá»c nhanh tá»« 500 xuá»‘ng 50 á»©ng viÃªn cháº¥t lÆ°á»£ng cao
- **CÃ¡ch hoáº¡t Ä‘á»™ng**:
  - Sá»­ dá»¥ng model nhá», nhanh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sÆ¡ bá»™
  - Káº¿t há»£p Ä‘iá»ƒm retrieval vá»›i Ä‘iá»ƒm light reranking
  - Chá»n top 50 á»©ng viÃªn Ä‘á»ƒ Ä‘Æ°a lÃªn táº§ng 3
- **Thá»i gian**: ~150ms
- **LÃ½ do**: Tiáº¿t kiá»‡m thá»i gian cho táº§ng 3

#### **4. Táº§ng 3: Tháº©m Ä‘á»‹nh chuyÃªn sÃ¢u (Ensemble)**
- **Má»¥c Ä‘Ã­ch**: Há»™i Ä‘á»“ng chuyÃªn gia tháº©m Ä‘á»‹nh vÃ  chá»n top 5 káº¿t quáº£
- **CÃ¡ch hoáº¡t Ä‘á»™ng**:
  - Sá»­ dá»¥ng nhiá»u model Cross-Encoder cÃ¹ng lÃºc
  - PhoBERT-Law + XLM-RoBERTa Ä‘Ã¡nh giÃ¡ song song
  - Láº¥y Ä‘iá»ƒm trung bÃ¬nh Ä‘á»ƒ ra quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng
- **Thá»i gian**: ~300ms
- **Äá»™ chÃ­nh xÃ¡c**: >90% (Precision@5)

#### **5. Tráº£ vá» káº¿t quáº£**
- **Output**: 5 vÄƒn báº£n phÃ¡p luáº­t phÃ¹ há»£p nháº¥t
- **ThÃ´ng tin bao gá»“m**:
  - Ná»™i dung Ä‘iá»u luáº­t
  - Äiá»ƒm sá»‘ tá»«ng táº§ng
  - ThÃ´ng tin bá»• sung (náº¿u cÃ³)

### **ğŸ§  Logic nghiá»‡p vá»¥ chi tiáº¿t:**

#### **Táº¡i sao cáº§n 3 táº§ng?**
1. **Táº§ng 1**: KhÃ´ng thá»ƒ bá» qua vÃ¬ cáº§n tÃ¬m kiáº¿m trong toÃ n bá»™ kho dá»¯ liá»‡u
2. **Táº§ng 2**: Cáº§n thiáº¿t Ä‘á»ƒ giáº£m táº£i cho táº§ng 3, trÃ¡nh lÃ£ng phÃ­ tÃ i nguyÃªn
3. **Táº§ng 3**: Cáº§n thiáº¿t Ä‘á»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Ä‘a cho káº¿t quáº£ cuá»‘i cÃ¹ng

#### **CÃ¡ch há»‡ thá»‘ng há»c há»i:**
1. **Hard Negative Mining**: Tá»± Ä‘á»™ng tÃ¬m nhá»¯ng vÃ­ dá»¥ khÃ³ nháº¥t Ä‘á»ƒ model há»c
2. **Domain-Adaptive Pre-training**: ChuyÃªn mÃ´n hÃ³a model cho phÃ¡p luáº­t
3. **Ensemble Learning**: Káº¿t há»£p nhiá»u Ã½ kiáº¿n chuyÃªn gia

#### **Äáº£m báº£o cháº¥t lÆ°á»£ng:**
1. **Validation**: Kiá»ƒm tra káº¿t quáº£ á»Ÿ má»—i táº§ng
2. **Logging**: Ghi láº¡i toÃ n bá»™ quÃ¡ trÃ¬nh Ä‘á»ƒ debug
3. **Monitoring**: Theo dÃµi hiá»‡u suáº¥t real-time

## ğŸ“Š **HIá»†U SUáº¤T Dá»° KIáº¾N**

Vá»›i kiáº¿n trÃºc 3 táº§ng vÃ  cÃ¡c ká»¹ thuáº­t tá»‘i Æ°u, há»‡ thá»‘ng Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng áº¥n tÆ°á»£ng:

### **ğŸ“ˆ Äá»™ chÃ­nh xÃ¡c theo tá»«ng táº§ng:**

| Metric | Táº§ng 1: Retrieval | Táº§ng 2: Light Reranking | Táº§ng 3: Strong Reranking |
|--------|-------------------|-------------------------|---------------------------|
| **Precision@5** | ~70% | ~80% | **> 90%** |
| **Recall@5** | ~60% | ~75% | **> 85%** |
| **MRR** | ~0.7 | ~0.8 | **> 0.85** |

### **âš¡ Thá»i gian xá»­ lÃ½:**

| TÃ¡c vá»¥ | Thá»i gian | MÃ´ táº£ |
|--------|-----------|-------|
| **Táº§ng 1**: Retrieval (500 á»©ng viÃªn) | ~100ms | TÃ¬m kiáº¿m rá»™ng trong toÃ n bá»™ kho dá»¯ liá»‡u |
| **Táº§ng 2**: Light Reranking (50 á»©ng viÃªn) | ~150ms | Lá»c nhanh vá»›i Light Reranker |
| **Táº§ng 3**: Strong Reranking (5 káº¿t quáº£) | ~300ms | Tháº©m Ä‘á»‹nh chuyÃªn sÃ¢u vá»›i Ensemble |
| **ğŸ“Š Tá»•ng thá»i gian pháº£n há»“i** | **~550ms** | **Nhanh hÆ¡n 10x so vá»›i tÃ¬m kiáº¿m thá»§ cÃ´ng** |

### **ğŸ¯ So sÃ¡nh vá»›i phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng:**

| TiÃªu chÃ­ | TÃ¬m kiáº¿m thá»§ cÃ´ng | LawBot v7.0 |
|----------|-------------------|-------------|
| **Thá»i gian** | 2-3 giá» | **30 giÃ¢y** |
| **Äá»™ chÃ­nh xÃ¡c** | 60-70% | **90%+** |
| **Kháº£ nÄƒng má»Ÿ rá»™ng** | Háº¡n cháº¿ | **KhÃ´ng giá»›i háº¡n** |
| **Chi phÃ­** | Cao (nhÃ¢n lá»±c) | **Tháº¥p** |



## ğŸ› ï¸ **PHÃT TRIá»‚N & Báº¢O TRÃŒ**

### **Kiá»ƒm tra cáº¥u trÃºc dá»± Ã¡n:**

```bash
# Kiá»ƒm tra cáº¥u trÃºc vÃ  best practices
python scripts/utils/check_project.py
```

### **Lá»c dá»¯ liá»‡u (náº¿u cáº§n):**

```bash
# Lá»c dá»¯ liá»‡u thÃ´ Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng
python scripts/utils/run_filter.py
```

### **Cháº¡y tá»«ng bÆ°á»›c riÃªng láº»:**

```bash
# BÆ°á»›c 0: DAPT (Domain-Adaptive Pre-training)
python scripts/00_adapt_model.py

# BÆ°á»›c 1: Kiá»ƒm tra mÃ´i trÆ°á»ng vÃ  xá»­ lÃ½ dá»¯ liá»‡u
python scripts/01_check_environment.py

# BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u training
python scripts/02_prepare_training_data.py

# BÆ°á»›c 3: Huáº¥n luyá»‡n models vÃ  Ä‘Ã¡nh giÃ¡
python scripts/03_train_models.py
```

## ğŸ“‹ **HÆ¯á»šNG DáºªN Váº¬N HÃ€NH**

### **CÃ¡c tÃ¡c vá»¥ hÃ ng ngÃ y:**

#### **1. GiÃ¡m sÃ¡t há»‡ thá»‘ng**
```bash
# Kiá»ƒm tra logs
tail -f logs/pipeline.log

# Kiá»ƒm tra hiá»‡u suáº¥t
python scripts/utils/check_performance.py

# Kiá»ƒm tra dung lÆ°á»£ng á»• cá»©ng
df -h
```

#### **2. Sao lÆ°u dá»¯ liá»‡u**
```bash
# Sao lÆ°u models
tar -czf models_backup_$(date +%Y%m%d).tar.gz models/

# Sao lÆ°u dá»¯ liá»‡u
tar -czf data_backup_$(date +%Y%m%d).tar.gz data/

# Sao lÆ°u indexes
tar -czf indexes_backup_$(date +%Y%m%d).tar.gz indexes/
```

#### **3. Báº£o trÃ¬ há»‡ thá»‘ng**
```bash
# Dá»n dáº¹p logs cÅ©
find logs/ -name "*.log" -mtime +30 -delete

# Dá»n dáº¹p checkpoints cÅ©
find checkpoints/ -name "*.pt" -mtime +7 -delete

# Cáº­p nháº­t dependencies
pip install -r requirements.txt --upgrade
```

### **Danh sÃ¡ch triá»ƒn khai:**

#### **1. TrÆ°á»›c khi triá»ƒn khai**
- [ ] Táº¥t cáº£ tests Ä‘á»u pass
- [ ] Code Ä‘Ã£ Ä‘Æ°á»£c review vÃ  approve
- [ ] Documentation Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t
- [ ] Performance benchmarks Ä‘áº¡t yÃªu cáº§u
- [ ] Security scan hoÃ n táº¥t

#### **2. Triá»ƒn khai**
- [ ] Sao lÆ°u phiÃªn báº£n hiá»‡n táº¡i
- [ ] Triá»ƒn khai phiÃªn báº£n má»›i
- [ ] Cháº¡y health checks
- [ ] GiÃ¡m sÃ¡t lá»—i
- [ ] XÃ¡c minh chá»©c nÄƒng

#### **3. Sau khi triá»ƒn khai**
- [ ] GiÃ¡m sÃ¡t performance metrics
- [ ] Kiá»ƒm tra feedback ngÆ°á»i dÃ¹ng
- [ ] Cáº­p nháº­t monitoring alerts
- [ ] Ghi láº¡i cÃ¡c váº¥n Ä‘á»

### **Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t (v8.0):**

#### **1. Tá»‘i Æ°u Model Parameters**
```python
# Bi-Encoder Optimizations (v8.0)
config.BI_ENCODER_BATCH_SIZE = 16                    # TÄƒng tá»« 4 lÃªn 16
config.BI_ENCODER_EPOCHS = 3                         # TÄƒng tá»« 1 lÃªn 3
config.BI_ENCODER_LR = 2e-5                          # TÄƒng tá»« 1e-7 lÃªn 2e-5
config.BI_ENCODER_WARMUP_STEPS = 100                 # TÄƒng tá»« 50 lÃªn 100
config.BI_ENCODER_EVAL_STEPS = 50                    # TÄƒng tá»« 25 lÃªn 50
config.BI_ENCODER_GRADIENT_ACCUMULATION_STEPS = 2    # Má»›i thÃªm

# Cross-Encoder Optimizations (v8.0)
config.CROSS_ENCODER_BATCH_SIZE = 8                  # TÄƒng tá»« 4 lÃªn 8
config.CROSS_ENCODER_EPOCHS = 5                      # TÄƒng tá»« 1 lÃªn 5
config.CROSS_ENCODER_LR = 2e-5                       # TÄƒng tá»« 5e-6 lÃªn 2e-5
config.CROSS_ENCODER_WARMUP_STEPS = 100              # TÄƒng tá»« 25 lÃªn 100
config.CROSS_ENCODER_EVAL_STEPS = 100                # TÄƒng tá»« 50 lÃªn 100
config.CROSS_ENCODER_GRADIENT_ACCUMULATION_STEPS = 4 # Má»›i thÃªm
```

#### **2. Tá»‘i Æ°u Operational Performance (v8.0)**
```python
# Mixed Precision Training (FP16)
config.FP16_TRAINING = True                           # TÄƒng tá»‘c Ä‘á»™ 1.5-2x, giáº£m 50% VRAM

# DataLoader Optimizations
config.BI_ENCODER_DATALOADER_NUM_WORKERS = 4         # TÄƒng tá»« 1 lÃªn 4
config.CROSS_ENCODER_DATALOADER_NUM_WORKERS = 4      # TÄƒng tá»« 1 lÃªn 4
config.BI_ENCODER_DATALOADER_PIN_MEMORY = True       # Tá»‘i Æ°u GPU transfer
config.CROSS_ENCODER_DATALOADER_PIN_MEMORY = True    # Tá»‘i Æ°u GPU transfer
config.BI_ENCODER_DATALOADER_PREFETCH_FACTOR = 2     # Má»›i thÃªm
config.CROSS_ENCODER_DATALOADER_PREFETCH_FACTOR = 2  # Má»›i thÃªm
```

#### **2. Tá»‘i Æ°u há»‡ thá»‘ng**
```bash
# TÄƒng file descriptors
ulimit -n 65536

# Tá»‘i Æ°u memory usage
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# Báº­t mixed precision
export CUDA_LAUNCH_BLOCKING=1
```

#### **3. Tá»‘i Æ°u FAISS Index**
```python
# FAISS index optimization
faiss.omp_set_num_threads(8)  # Set sá»‘ threads
index.nprobe = 64             # Äiá»u chá»‰nh search parameters
```

### **Kiá»ƒm tra cáº¥u trÃºc dá»± Ã¡n:**

```bash
# Kiá»ƒm tra cáº¥u trÃºc project vÃ  best practices
python scripts/utils/check_project.py
```

## ğŸ“š **API DOCUMENTATION**

### **LegalQAPipeline**

Class chÃ­nh Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i há»‡ thá»‘ng.

```python
from core.pipeline import LegalQAPipeline

# Khá»Ÿi táº¡o
pipeline = LegalQAPipeline()

# Kiá»ƒm tra tráº¡ng thÃ¡i
if pipeline.is_ready:
    print("Pipeline sáºµn sÃ ng!")
else:
    print("Pipeline chÆ°a sáºµn sÃ ng!")
```

#### **Methods:**

##### `predict(query, top_k_retrieval=100, top_k_final=5)`

Dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i cho cÃ¢u há»i.

**Parameters:**
- `query` (str): CÃ¢u há»i cáº§n tráº£ lá»i
- `top_k_retrieval` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£ retrieval (default: 100)
- `top_k_final` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£ cuá»‘i cÃ¹ng (default: 5)

**Returns:**
- `List[Dict]`: Danh sÃ¡ch káº¿t quáº£ vá»›i format:
  ```python
  [
      {
          "aid": "law_1_113",
          "content": "Äiá»u 113: NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
          "retrieval_score": 0.85,
          "rerank_score": 0.92
      },
      # ...
  ]
  ```

**VÃ­ dá»¥ sá»­ dá»¥ng:**
```python
# Input
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"

# Output
results = [
    {
        "aid": "law_1_113",
        "content": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm 12 ngÃ y lÃ m viá»‡c...",
        "retrieval_score": 0.85,
        "rerank_score": 0.92
    },
    {
        "aid": "law_1_114",
        "content": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm Ä‘Æ°á»£c tÃ­nh theo nÄƒm lÃ m viá»‡c...",
        "retrieval_score": 0.78,
        "rerank_score": 0.87
    }
]
```

##### `retrieve(query, top_k=100)`

Chá»‰ thá»±c hiá»‡n retrieval (táº§ng 1).

**Parameters:**
- `query` (str): CÃ¢u há»i
- `top_k` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£

**Returns:**
- `Tuple[List[str], List[float]]`: (aids, scores)

**VÃ­ dá»¥:**
```python
# Input
query = "Äiá»u kiá»‡n thÃ nh láº­p doanh nghiá»‡p?"

# Output
aids = ["law_2_15", "law_2_16", "law_2_17", ...]
scores = [0.95, 0.87, 0.82, ...]
```

##### `rerank(query, retrieved_aids, retrieved_distances)`

Chá»‰ thá»±c hiá»‡n reranking (táº§ng 2).

**Parameters:**
- `query` (str): CÃ¢u há»i
- `retrieved_aids` (List[str]): Danh sÃ¡ch AIDs tá»« retrieval
- `retrieved_distances` (List[float]): Äiá»ƒm sá»‘ tá»« retrieval

**Returns:**
- `List[Dict]`: Káº¿t quáº£ Ä‘Ã£ rerank

**VÃ­ dá»¥:**
```python
# Input
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
retrieved_aids = ["law_1_113", "law_1_114", "law_1_115"]
retrieved_distances = [0.85, 0.78, 0.72]

# Output
reranked_results = [
    {
        "aid": "law_1_113",
        "content": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
        "retrieval_score": 0.85,
        "rerank_score": 0.92
    },
    {
        "aid": "law_1_114", 
        "content": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm...",
        "retrieval_score": 0.78,
        "rerank_score": 0.87
    }
]
```

## ğŸ› ï¸ **UTILITIES**

### **Dataset Filtering Utility**

Script Ä‘á»ƒ lá»c dataset trÆ°á»›c khi cháº¡y pipeline chÃ­nh:

```bash
# Cháº¡y filtering utility
python scripts/utils/run_filter.py

# Hoáº·c cháº¡y trá»±c tiáº¿p
python scripts/utils/filter_dataset.py
```

**Chá»©c nÄƒng:**
- Lá»c bá» samples cÃ³ ground truth khÃ´ng phÃ¹ há»£p
- Giá»¯ láº¡i ~100-200 samples cháº¥t lÆ°á»£ng cao
- Cáº£i thiá»‡n cháº¥t lÆ°á»£ng dá»¯ liá»‡u training

### **Project Structure Checker**

Kiá»ƒm tra cáº¥u trÃºc project vÃ  best practices:

```bash
python scripts/utils/check_project.py
```

**Chá»©c nÄƒng:**
- Kiá»ƒm tra cáº¥u trÃºc thÆ° má»¥c
- Validate naming conventions
- Kiá»ƒm tra documentation
- Äáº£m báº£o best practices

## ğŸ› ï¸ **DEVELOPMENT & BEST PRACTICES**

### **Project Structure Check:**

```bash
# Kiá»ƒm tra cáº¥u trÃºc project vÃ  best practices
python scripts/utils/check_project.py
```

### **Code Quality Standards:**

```bash
# Format code
black .

# Lint code
flake8 .

# Type checking
mypy .

# Run tests
pytest tests/
```

### **Best Practices Applied:**

#### **1. Separation of Concerns**
- **Pipeline Scripts**: Má»—i script cÃ³ má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ
- **Utility Scripts**: TÃ¡ch riÃªng vÃ o thÆ° má»¥c `scripts/utils/`
- **Core Modules**: TÃ¡ch biá»‡t logic nghiá»‡p vá»¥ vÃ  infrastructure

#### **2. Naming Conventions**
- **Pipeline Steps**: `01_`, `02_`, `03_` prefix cho cÃ¡c bÆ°á»›c chÃ­nh
- **Utility Scripts**: TÃªn mÃ´ táº£ rÃµ chá»©c nÄƒng
- **Functions**: snake_case cho Python functions
- **Classes**: PascalCase cho class names

#### **3. Error Handling**
- **Graceful Degradation**: Há»‡ thá»‘ng váº«n hoáº¡t Ä‘á»™ng khi cÃ³ lá»—i
- **Detailed Logging**: Log Ä‘áº§y Ä‘á»§ thÃ´ng tin lá»—i
- **User-Friendly Messages**: ThÃ´ng bÃ¡o lá»—i dá»… hiá»ƒu

#### **4. Configuration Management**
- **Environment Variables**: Há»— trá»£ cáº¥u hÃ¬nh qua env vars
- **Centralized Config**: Táº¥t cáº£ config trong `config.py`
- **Validation**: Kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a config

### **Performance Optimization:**

#### **1. Memory Management**
- **Batch Processing**: Xá»­ lÃ½ theo batch Ä‘á»ƒ tiáº¿t kiá»‡m memory
- **GPU Utilization**: Tá»‘i Æ°u sá»­ dá»¥ng GPU
- **Model Caching**: Cache models Ä‘á»ƒ trÃ¡nh load láº¡i

#### **2. Speed Optimization**
- **FAISS Index**: Sá»­ dá»¥ng FAISS cho retrieval nhanh
- **Parallel Processing**: Xá»­ lÃ½ song song khi cÃ³ thá»ƒ
- **Efficient Data Structures**: Sá»­ dá»¥ng cáº¥u trÃºc dá»¯ liá»‡u hiá»‡u quáº£

## ğŸ”„ **TECHNICAL ARCHITECTURE DETAILS**

### **Core Components:**

#### **1. Bi-Encoder (Retrieval Layer)**
```python
# Model: bkai-foundation-models/vietnamese-bi-encoder
# Purpose: Encode questions and documents into vectors
# Output: 768-dimensional embeddings
# Usage: FAISS similarity search

class BiEncoderComponent:
    def encode(self, texts: List[str]) -> np.ndarray:
        """Encode texts to embeddings"""
        embeddings = self.model.encode(texts, convert_to_tensor=True)
        return embeddings.cpu().numpy()
    
    def search(self, query_embedding: np.ndarray, top_k: int) -> Tuple[List[int], List[float]]:
        """Search similar documents using FAISS"""
        distances, indices = self.faiss_index.search(query_embedding, top_k)
        return indices, distances
```

#### **2. Cross-Encoder (Reranking Layer)**
```python
# Model: vinai/phobert-large
# Purpose: Score question-document pairs
# Input: [CLS] question [SEP] document [SEP]
# Output: Binary classification score (0-1)

class CrossEncoderComponent:
    def score_pairs(self, pairs: List[List[str]]) -> List[float]:
        """Score question-document pairs"""
        tokenized = self.tokenizer(
            pairs,
            padding=True,
            truncation=True,
            max_length=256,
            return_tensors="pt"
        )
        
        with torch.no_grad():
            logits = self.model(**tokenized).logits
            scores = torch.softmax(logits, dim=1)[:, 1].cpu().tolist()
        
        return scores
```

#### **3. FAISS Index**
```python
# Type: IndexFlatIP (Inner Product)
# Dimension: 768
# Normalization: L2 normalization
# Size: ~100MB for 100K documents

class FAISSIndex:
    def __init__(self, dimension: int = 768):
        self.index = faiss.IndexFlatIP(dimension)
        self.index_to_aid = {}
    
    def add_documents(self, embeddings: np.ndarray, aids: List[str]):
        """Add document embeddings to index"""
        faiss.normalize_L2(embeddings)
        self.index.add(embeddings)
        
        # Map index positions to AIDs
        start_idx = len(self.index_to_aid)
        for i, aid in enumerate(aids):
            self.index_to_aid[start_idx + i] = aid
```

### **Data Flow Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data      â”‚â”€â”€â”€â–¶â”‚  Preprocessing  â”‚â”€â”€â”€â–¶â”‚  Training Data  â”‚
â”‚   (JSON files)  â”‚    â”‚  Pipeline       â”‚    â”‚  (Triplets/Pairs)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Models        â”‚â—€â”€â”€â”€â”‚  Training       â”‚â—€â”€â”€â”€â”‚  Model Config   â”‚
â”‚   (Saved)       â”‚    â”‚  Pipeline       â”‚    â”‚  (Hyperparams)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FAISS Index   â”‚â—€â”€â”€â”€â”‚  Index Building â”‚â—€â”€â”€â”€â”‚  Document       â”‚
â”‚   (Binary)      â”‚    â”‚  Pipeline       â”‚    â”‚  Embeddings     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Request Processing Pipeline:**

#### **1. Input Validation**
```python
def validate_query(query: str) -> bool:
    """Validate input query"""
    if not query or len(query.strip()) == 0:
        return False
    if len(query) > 1000:  # Max length
        return False
    return True
```

#### **2. Retrieval Phase**
```python
def retrieval_phase(query: str, top_k: int = 100) -> Tuple[List[str], List[float]]:
    """Phase 1: Retrieve relevant documents"""
    # 1. Encode query
    query_embedding = bi_encoder.encode([query])
    
    # 2. Search FAISS index
    distances, indices = faiss_index.search(query_embedding, top_k)
    
    # 3. Convert to AIDs
    retrieved_aids = [index_to_aid[i] for i in indices[0]]
    
    return retrieved_aids, distances[0]
```

#### **3. Reranking Phase**
```python
def reranking_phase(query: str, retrieved_aids: List[str]) -> List[Dict]:
    """Phase 2: Rerank retrieved documents"""
    # 1. Get document contents
    documents = [aid_map[aid] for aid in retrieved_aids]
    
    # 2. Create pairs
    pairs = [[query, doc] for doc in documents]
    
    # 3. Score pairs
    scores = cross_encoder.score_pairs(pairs)
    
    # 4. Create results
    results = [
        {
            "aid": aid,
            "content": doc,
            "rerank_score": score
        }
        for aid, doc, score in zip(retrieved_aids, documents, scores)
    ]
    
    return sorted(results, key=lambda x: x["rerank_score"], reverse=True)
```

### **Performance Metrics:**

#### **1. Retrieval Metrics**
- **Precision@K**: Tá»· lá»‡ documents liÃªn quan trong top-K
- **Recall@K**: Tá»· lá»‡ documents liÃªn quan Ä‘Æ°á»£c tÃ¬m tháº¥y
- **F1@K**: Harmonic mean cá»§a Precision vÃ  Recall
- **MRR**: Mean Reciprocal Rank

#### **2. Reranking Metrics**
- **Accuracy**: Äá»™ chÃ­nh xÃ¡c cá»§a binary classification
- **AUC-ROC**: Area under ROC curve
- **Precision-Recall**: Trade-off giá»¯a precision vÃ  recall

#### **3. End-to-End Metrics**
- **Response Time**: Thá»i gian xá»­ lÃ½ tá»« request Ä‘áº¿n response
- **Throughput**: Sá»‘ requests xá»­ lÃ½ Ä‘Æ°á»£c trong 1 giÃ¢y
- **Memory Usage**: LÆ°á»£ng memory sá»­ dá»¥ng

## ğŸš¨ **TROUBLESHOOTING**

Tham kháº£o cÃ¡c lá»—i thÆ°á»ng gáº·p vÃ  cÃ¡ch kháº¯c phá»¥c chi tiáº¿t trong file `QUICK_START.md` hoáº·c `DEPLOYMENT_GUIDE.md`.

## ğŸ“– **TÃ€I LIá»†U THAM KHáº¢O**

### **Papers:**
- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)
- [Cross-Encoders vs. Bi-Encoders for Zero-Shot Classification](https://arxiv.org/abs/2108.08877)
- [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906)

### **Libraries:**
- [Sentence Transformers](https://www.sbert.net/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Transformers](https://huggingface.co/transformers/)
- [PyTorch](https://pytorch.org/)

### **Datasets:**
- [Vietnamese Legal Corpus](https://github.com/lawbot-team/vietnamese-legal-corpus)
- [Legal QA Dataset](https://github.com/lawbot-team/legal-qa-dataset)

## ğŸ¤ **ÄÃ“NG GÃ“P**

ChÃºng tÃ´i ráº¥t hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p! Vui lÃ²ng Ä‘á»c `CONTRIBUTING.md` Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ“„ **LICENSE**

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c cáº¥p phÃ©p theo MIT License.

---

**Made with â¤ï¸ by LawBot Team**
