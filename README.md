# ğŸ›ï¸ LawBot - Legal QA Pipeline

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-2.0.0-green.svg)](https://github.com/lawbot-team/lawbot)

> **Há»‡ thá»‘ng há»i-Ä‘Ã¡p phÃ¡p luáº­t thÃ´ng minh cho Viá»‡t Nam**  
> Sá»­ dá»¥ng kiáº¿n trÃºc Retrieval-Rerank vá»›i Bi-Encoder vÃ  Cross-Encoder

## ğŸ“‹ **Tá»”NG QUAN (WHAT)**

### **LawBot lÃ  gÃ¬?**
LawBot lÃ  má»™t há»‡ thá»‘ng há»i-Ä‘Ã¡p phÃ¡p luáº­t tiÃªn tiáº¿n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho phÃ¡p luáº­t Viá»‡t Nam. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ´ng nghá»‡ AI hiá»‡n Ä‘áº¡i Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» phÃ¡p luáº­t má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  nhanh chÃ³ng.

### **Kiáº¿n trÃºc há»‡ thá»‘ng:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CÃ¢u há»i      â”‚â”€â”€â”€â–¶â”‚  Bi-Encoder     â”‚â”€â”€â”€â–¶â”‚  Top-K Results  â”‚
â”‚   cá»§a ngÆ°á»i    â”‚    â”‚  (Retrieval)    â”‚    â”‚  (100 docs)     â”‚
â”‚   dÃ¹ng         â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CÃ¢u tráº£ lá»i  â”‚â—€â”€â”€â”€â”‚  Cross-Encoder  â”‚â—€â”€â”€â”€â”‚  Re-ranked      â”‚
â”‚   chÃ­nh xÃ¡c    â”‚    â”‚  (Reranking)    â”‚    â”‚  Top-5 Results  â”‚
â”‚   nháº¥t         â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **CÃ¡ch hoáº¡t Ä‘á»™ng:**
1. **ğŸ” Retrieval (Bi-Encoder)**: TÃ¬m 100 vÄƒn báº£n phÃ¡p luáº­t liÃªn quan nháº¥t
2. **âš–ï¸ Reranking (Cross-Encoder)**: ÄÃ¡nh giÃ¡ vÃ  sáº¯p xáº¿p láº¡i top 5 káº¿t quáº£ chÃ­nh xÃ¡c nháº¥t
3. **ğŸ“¤ Output**: Tráº£ vá» 5 vÄƒn báº£n phÃ¡p luáº­t phÃ¹ há»£p nháº¥t vá»›i Ä‘iá»ƒm sá»‘

## ğŸ¯ **Táº I SAO Cáº¦N LAW BOT? (WHY)**

### **Váº¥n Ä‘á» hiá»‡n táº¡i:**
- âŒ **KhÃ³ tÃ¬m kiáº¿m**: VÄƒn báº£n phÃ¡p luáº­t ráº¥t nhiá»u vÃ  phá»©c táº¡p
- âŒ **Thá»i gian cháº­m**: TÃ¬m kiáº¿m thá»§ cÃ´ng máº¥t nhiá»u thá»i gian
- âŒ **Thiáº¿u chÃ­nh xÃ¡c**: Káº¿t quáº£ tÃ¬m kiáº¿m khÃ´ng Ä‘Ãºng trá»ng tÃ¢m
- âŒ **KhÃ³ hiá»ƒu**: NgÃ´n ngá»¯ phÃ¡p lÃ½ khÃ³ hiá»ƒu vá»›i ngÆ°á»i khÃ´ng chuyÃªn

### **Giáº£i phÃ¡p LawBot:**
- âœ… **TÃ¬m kiáº¿m nhanh**: AI tÃ¬m kiáº¿m trong vÃ i giÃ¢y
- âœ… **Káº¿t quáº£ chÃ­nh xÃ¡c**: Sá»­ dá»¥ng Cross-Encoder Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ liÃªn quan
- âœ… **Dá»… hiá»ƒu**: Tráº£ vá» vÄƒn báº£n phÃ¡p luáº­t cÃ³ liÃªn quan nháº¥t
- âœ… **Tiáº¿t kiá»‡m thá»i gian**: Tá»« vÃ i giá» xuá»‘ng cÃ²n vÃ i giÃ¢y

## â° **KHI NÃ€O Sá»¬ Dá»¤NG? (WHEN)**

### **CÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng:**
- ğŸ” **TÃ¬m kiáº¿m luáº­t**: "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
- ğŸ“‹ **Tra cá»©u quy Ä‘á»‹nh**: "Äiá»u kiá»‡n thÃ nh láº­p doanh nghiá»‡p lÃ  gÃ¬?"
- âš–ï¸ **So sÃ¡nh vÄƒn báº£n**: "Sá»± khÃ¡c biá»‡t giá»¯a Luáº­t Doanh nghiá»‡p cÅ© vÃ  má»›i?"
- ğŸ“ **TÃ¬m Ä‘iá»u khoáº£n**: "Äiá»u 113 Bá»™ luáº­t Lao Ä‘á»™ng quy Ä‘á»‹nh gÃ¬?"

### **Khi nÃ o KHÃ”NG sá»­ dá»¥ng:**
- âŒ CÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n phÃ¡p luáº­t
- âŒ YÃªu cáº§u tÆ° váº¥n phÃ¡p lÃ½ chuyÃªn sÃ¢u
- âŒ Thay tháº¿ hoÃ n toÃ n luáº­t sÆ°

## ğŸ“ **Sá»¬ Dá»¤NG á» ÄÃ‚U? (WHERE)**

### **MÃ´i trÆ°á»ng phÃ¡t triá»ƒn:**
- ğŸ’» **Local Development**: MÃ¡y tÃ­nh cÃ¡ nhÃ¢n
- ğŸ–¥ï¸ **Server**: MÃ¡y chá»§ cÃ´ng ty
- â˜ï¸ **Cloud**: AWS, Google Cloud, Azure
- ğŸ³ **Docker**: Container deployment

### **YÃªu cáº§u há»‡ thá»‘ng:**
```
OS: Windows 10+, Ubuntu 18.04+, macOS 10.14+
RAM: Tá»‘i thiá»ƒu 8GB, khuyáº¿n nghá»‹ 16GB+
Storage: Tá»‘i thiá»ƒu 10GB cho models vÃ  data
GPU: NVIDIA GPU vá»›i CUDA (khuyáº¿n nghá»‹)
Python: 3.8+
```

## ğŸ‘¥ **AI CHO? (WHO)**

### **Äá»‘i tÆ°á»£ng sá»­ dá»¥ng:**
- ğŸ‘¨â€ğŸ’¼ **Luáº­t sÆ°**: Tra cá»©u nhanh vÄƒn báº£n phÃ¡p luáº­t
- ğŸ‘¨â€ğŸ’» **NhÃ  phÃ¡t triá»ƒn**: TÃ­ch há»£p vÃ o á»©ng dá»¥ng phÃ¡p lÃ½
- ğŸ‘¨â€ğŸ“ **Sinh viÃªn luáº­t**: Há»c táº­p vÃ  nghiÃªn cá»©u
- ğŸ‘¨â€ğŸ’¼ **Doanh nghiá»‡p**: TuÃ¢n thá»§ quy Ä‘á»‹nh phÃ¡p luáº­t
- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **CÃ´ng dÃ¢n**: TÃ¬m hiá»ƒu quyá»n vÃ  nghÄ©a vá»¥

### **Äá»‘i tÆ°á»£ng phÃ¡t triá»ƒn:**
- ğŸ‘¨â€ğŸ’» **AI/ML Engineers**: PhÃ¡t triá»ƒn vÃ  tá»‘i Æ°u models
- ğŸ‘¨â€ğŸ’» **Software Engineers**: TÃ­ch há»£p vÃ  deployment
- ğŸ‘¨â€ğŸ’» **Data Scientists**: PhÃ¢n tÃ­ch vÃ  cáº£i thiá»‡n performance
- ğŸ‘¨â€ğŸ’» **DevOps Engineers**: Deployment vÃ  monitoring

## ğŸ”§ **LÃ€M THáº¾ NÃ€O? (HOW)**

## ğŸš€ **QUICK START**

### **BÆ°á»›c 1: CÃ i Ä‘áº·t**

```bash
# Clone repository
git clone https://github.com/lawbot-team/lawbot.git
cd lawbot

# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Hoáº·c cÃ i Ä‘áº·t nhÆ° package
pip install -e .
```

### **BÆ°á»›c 2: Kiá»ƒm tra mÃ´i trÆ°á»ng**

```bash
python scripts/01_check_environment.py
```

### **BÆ°á»›c 3: Cháº¡y pipeline**

```bash
# Cháº¡y toÃ n bá»™ pipeline
python run_pipeline.py

# Cháº¡y tá»« bÆ°á»›c cá»¥ thá»ƒ
python run_pipeline.py --step 05

# Bá» qua filtering
python run_pipeline.py --skip-filtering

# Xem danh sÃ¡ch bÆ°á»›c
python run_pipeline.py --list-steps
```

### **BÆ°á»›c 4: Sá»­ dá»¥ng API**

```python
from core.pipeline import LegalQAPipeline

# Khá»Ÿi táº¡o pipeline
pipeline = LegalQAPipeline()

# Há»i Ä‘Ã¡p
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
results = pipeline.predict(
    query=query,
    top_k_retrieval=100,
    top_k_final=5
)

# In káº¿t quáº£
for i, result in enumerate(results):
    print(f"Káº¿t quáº£ {i+1}: {result['aid']}")
    print(f"Äiá»ƒm: {result['rerank_score']:.4f}")
    print(f"Ná»™i dung: {result['content'][:200]}...")
    print("-" * 50)
```

## ğŸ“ **Cáº¤U TRÃšC PROJECT**

```
LawBot/
â”œâ”€â”€ ğŸ“ core/                    # Core utilities
â”‚   â”œâ”€â”€ logging_utils.py        # Unified logging
â”‚   â”œâ”€â”€ data_utils.py           # Data processing
â”‚   â”œâ”€â”€ model_utils.py          # Model utilities
â”‚   â”œâ”€â”€ evaluation_utils.py     # Evaluation metrics
â”‚   â””â”€â”€ pipeline_utils.py       # Pipeline orchestration
â”‚
â”œâ”€â”€ ğŸ“ scripts/                 # Pipeline scripts
â”‚   â”œâ”€â”€ 01_check_environment.py
â”‚   â”œâ”€â”€ 02_filter_dataset.py
â”‚   â”œâ”€â”€ 03_preprocess_data.py
â”‚   â”œâ”€â”€ 04_split_data.py
â”‚   â”œâ”€â”€ 05_validate_mapping.py
â”‚   â”œâ”€â”€ 06_prepare_training_data.py
â”‚   â”œâ”€â”€ 07_merge_data.py
â”‚   â”œâ”€â”€ 08_augment_data.py
â”‚   â”œâ”€â”€ 09_train_bi_encoder.py
â”‚   â”œâ”€â”€ 10_build_faiss_index.py
â”‚   â”œâ”€â”€ 11_train_cross_encoder.py
â”‚   â””â”€â”€ 12_evaluate_pipeline.py
â”‚
â”œâ”€â”€ ğŸ“ data/                    # Data directories
â”‚   â”œâ”€â”€ raw/                    # Original data
â”‚   â”œâ”€â”€ processed/              # Processed data
â”‚   â””â”€â”€ validation/             # Validation data
â”‚
â”œâ”€â”€ ğŸ“ models/                  # Trained models
â”‚   â”œâ”€â”€ bi_encoder/
â”‚   â””â”€â”€ cross_encoder/
â”‚
â”œâ”€â”€ ğŸ“ indexes/                 # FAISS indexes
â”œâ”€â”€ ğŸ“ reports/                 # Evaluation reports
â”œâ”€â”€ ğŸ“ logs/                    # Log files
â”œâ”€â”€ ğŸ“ app/                     # Web application
â”‚
â”œâ”€â”€ ğŸ“„ config.py                # Configuration
â”œâ”€â”€ ğŸ“„ run_pipeline.py          # Main pipeline runner
â”œâ”€â”€ ğŸ“„ setup.py                 # Package setup
â”œâ”€â”€ ğŸ“„ requirements.txt         # Dependencies
â””â”€â”€ ğŸ“„ README.md               # Documentation
```

## ğŸ”§ **Cáº¤U HÃŒNH**

### **Environment Variables**

Báº¡n cÃ³ thá»ƒ cáº¥u hÃ¬nh LawBot thÃ´ng qua environment variables:

```bash
# Environment
export LAWBOT_ENV=production
export LAWBOT_DEBUG=false

# Directories
export LAWBOT_DATA_DIR=/path/to/data
export LAWBOT_MODELS_DIR=/path/to/models
export LAWBOT_INDEXES_DIR=/path/to/indexes

# Hyperparameters
export LAWBOT_BI_ENCODER_BATCH_SIZE=8
export LAWBOT_CROSS_ENCODER_BATCH_SIZE=4
export LAWBOT_BI_ENCODER_LR=1e-7
export LAWBOT_CROSS_ENCODER_LR=5e-6

# Pipeline settings
export LAWBOT_TOP_K_RETRIEVAL=100
export LAWBOT_TOP_K_FINAL=5
```

### **Configuration File**

Táº¥t cáº£ cáº¥u hÃ¬nh Ä‘Æ°á»£c quáº£n lÃ½ trong `config.py`:

```python
import config

# In thÃ´ng tin cáº¥u hÃ¬nh
config.print_config_summary()

# Validate cáº¥u hÃ¬nh
config.validate_config()
```

## ğŸ“Š **PIPELINE FLOW CHI TIáº¾T**

### **ğŸ¯ Quy trÃ¬nh 12 bÆ°á»›c vá»›i Input/Output:**

#### **BÆ°á»›c 01: Kiá»ƒm tra mÃ´i trÆ°á»ng**
```bash
# Input: KhÃ´ng cÃ³
python scripts/01_check_environment.py

# Output: BÃ¡o cÃ¡o mÃ´i trÆ°á»ng
âœ… Python version: 3.8.0
âœ… CUDA available: True
âœ… Required packages installed
âœ… Data files found
âœ… Directories created
```

#### **BÆ°á»›c 02: Lá»c dataset cháº¥t lÆ°á»£ng**
```bash
# Input: data/raw/train.json
python scripts/02_filter_dataset.py

# Output: data/raw/train_filtered.json
# Loáº¡i bá» 70-90% samples cÃ³ ground truth khÃ´ng phÃ¹ há»£p
# Giá»¯ láº¡i ~100-200 samples cháº¥t lÆ°á»£ng cao
```

#### **BÆ°á»›c 03: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Fixed Mapping)**
```bash
# Input: 
# - data/raw/legal_corpus.json
# - data/raw/train_filtered.json

python scripts/03_preprocess_data.py

# Output:
# - data/processed/aid_map.pkl (Article ID mapping)
# - data/processed/doc_id_to_aids_complete.json (Document to AIDs mapping)
# - data/processed/train_fixed.json (Fixed training data)
```

**VÃ­ dá»¥ Input/Output:**
```json
// Input: legal_corpus.json
{
  "doc_id": 1,
  "content": [
    {
      "aid": "law_1_113",
      "content_Article": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm..."
    }
  ]
}

// Output: aid_map.pkl
{
  "law_1_113": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
  "law_1_114": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm Ä‘Æ°á»£c tÃ­nh..."
}
```

#### **BÆ°á»›c 04: Chia dá»¯ liá»‡u train/validation**
```bash
# Input: data/processed/train_fixed.json
python scripts/04_split_data.py

# Output:
# - data/raw/train_split.json (85% training)
# - data/raw/validation_split.json (15% validation)
```

**VÃ­ dá»¥ Input/Output:**
```json
// Input: train_fixed.json (100 samples)
[
  {
    "question": "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?",
    "relevant_aids": ["law_1_113", "law_1_114"]
  }
]

// Output: train_split.json (85 samples)
// Output: validation_split.json (15 samples)
```

#### **BÆ°á»›c 05: Validate mapping**
```bash
# Input: 
# - data/processed/aid_map.pkl
# - data/raw/validation_split.json

python scripts/05_validate_mapping.py

# Output: BÃ¡o cÃ¡o validation
âœ… Mapping validation passed
âœ… All AIDs in validation set exist in aid_map
âœ… Ground truth format correct
```

#### **BÆ°á»›c 06: Chuáº©n bá»‹ training data**
```bash
# Input: data/raw/train_split.json
python scripts/06_prepare_training_data.py

# Output:
# - data/processed/train_triplets_easy.jsonl (Bi-Encoder triplets)
# - data/processed/train_pairs.jsonl (Cross-Encoder pairs)
# - data/processed/bi_encoder_validation.jsonl (Validation data)
```

**VÃ­ dá»¥ Input/Output:**
```json
// Input: train_split.json
{
  "question": "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?",
  "relevant_aids": ["law_1_113", "law_1_114"]
}

// Output: train_triplets_easy.jsonl
{
  "anchor": "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?",
  "positive": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
  "negative": "Äiá»u 200. Quy Ä‘á»‹nh vá» thá»i gian lÃ m viá»‡c..."
}

// Output: train_pairs.jsonl
{
  "texts": [
    "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?",
    "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm..."
  ],
  "labels": 1
}
```

#### **BÆ°á»›c 07: Merge dá»¯ liá»‡u**
```bash
# Input: 
# - data/processed/train_triplets_easy.jsonl
# - data/processed/train_pairs.jsonl

python scripts/07_merge_data.py

# Output:
# - data/processed/bi_encoder_train_mixed.jsonl (Easy + Hard negatives)
# - data/processed/train_pairs_mixed.jsonl (Easy + Hard negatives)
```

#### **BÆ°á»›c 08: Augment dá»¯ liá»‡u**
```bash
# Input: 
# - data/processed/bi_encoder_train_mixed.jsonl
# - data/processed/train_pairs_mixed.jsonl

python scripts/08_augment_data.py

# Output:
# - data/processed/bi_encoder_train_augmented.jsonl (1.5x size)
# - data/processed/train_pairs_augmented.jsonl (1.3x size)
```

**VÃ­ dá»¥ Augmentation:**
```json
// Input
{
  "anchor": "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?",
  "positive": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
  "negative": "Äiá»u 200. Quy Ä‘á»‹nh vá» thá»i gian lÃ m viá»‡c..."
}

// Output (Augmented)
{
  "anchor": "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?",
  "positive": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm 12 ngÃ y lÃ m viá»‡c...",
  "negative": "Äiá»u 200. Quy Ä‘á»‹nh vá» thá»i gian lÃ m viá»‡c vÃ  nghá»‰ ngÆ¡i..."
}
```

#### **BÆ°á»›c 09: Train Bi-Encoder**
```bash
# Input: data/processed/bi_encoder_train_augmented.jsonl
python scripts/09_train_bi_encoder.py

# Output: models/bi-encoder/
# - config.json
# - pytorch_model.bin
# - tokenizer.json
# - special_tokens_map.json
```

**Training Configuration:**
```python
# Hyperparameters
batch_size = 4
epochs = 1
learning_rate = 1e-7
warmup_steps = 50
eval_steps = 25

# Loss: MultipleNegativesRankingLoss
# Model: bkai-foundation-models/vietnamese-bi-encoder
```

#### **BÆ°á»›c 10: Build FAISS index**
```bash
# Input: 
# - models/bi-encoder/ (trained model)
# - data/processed/aid_map.pkl

python scripts/10_build_faiss_index.py

# Output:
# - indexes/legal.faiss (FAISS index)
# - indexes/index_to_aid.json (Index to AID mapping)
```

**Index Structure:**
```python
# FAISS Index
index_type = "IndexFlatIP"  # Inner Product
dimension = 768
normalize = True

# Index size: ~100MB for 100K documents
# Search time: 50-100ms for 100 results
```

#### **BÆ°á»›c 11: Train Cross-Encoder**
```bash
# Input: data/processed/train_pairs_augmented.jsonl
python scripts/11_train_cross_encoder.py

# Output: models/cross-encoder-v2/
# - config.json
# - pytorch_model.bin
# - tokenizer.json
```

**Training Configuration:**
```python
# Hyperparameters
batch_size = 4
epochs = 1
learning_rate = 5e-6
max_length = 256
gradient_accumulation_steps = 4

# Model: vinai/phobert-large
# Input format: [CLS] query [SEP] document [SEP]
# Output: Binary classification (relevant/not relevant)
```

#### **BÆ°á»›c 12: ÄÃ¡nh giÃ¡ pipeline**
```bash
# Input: 
# - models/bi-encoder/
# - models/cross-encoder-v2/
# - indexes/legal.faiss
# - data/raw/validation_split.json

python scripts/12_evaluate_pipeline.py

# Output: reports/evaluation_report_*.json
```

**Evaluation Metrics:**
```json
{
  "retrieval_metrics": {
    "precision@1": 0.75,
    "precision@5": 0.80,
    "recall@5": 0.70,
    "f1@5": 0.75,
    "mrr": 0.78
  },
  "reranking_metrics": {
    "precision@1": 0.85,
    "precision@5": 0.82,
    "recall@5": 0.75,
    "f1@5": 0.78,
    "mrr": 0.82
  }
}
```

### **ğŸ§  Kiáº¿n trÃºc xá»­ lÃ½ chi tiáº¿t:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CÃ¢u há»i      â”‚â”€â”€â”€â–¶â”‚  Bi-Encoder     â”‚â”€â”€â”€â–¶â”‚  Top-K Results  â”‚
â”‚   cá»§a ngÆ°á»i    â”‚    â”‚  (Retrieval)    â”‚    â”‚  (100 docs)     â”‚
â”‚   dÃ¹ng         â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CÃ¢u tráº£ lá»i  â”‚â—€â”€â”€â”€â”‚  Cross-Encoder  â”‚â—€â”€â”€â”€â”‚  Re-ranked      â”‚
â”‚   chÃ­nh xÃ¡c    â”‚    â”‚  (Reranking)    â”‚    â”‚  Top-5 Results  â”‚
â”‚   nháº¥t         â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ **PERFORMANCE**

### **ğŸ¯ Metrics dá»± kiáº¿n:**

| Metric | Bi-Encoder | Cross-Encoder | Pipeline |
|--------|------------|---------------|----------|
| **Precision@5** | 60-70% | 75-85% | 80-90% |
| **Recall@5** | 50-60% | 65-75% | 70-80% |
| **F1@5** | 55-65% | 70-80% | 75-85% |
| **MRR** | 0.6-0.7 | 0.7-0.8 | 0.75-0.85 |

### **âš¡ Thá»i gian xá»­ lÃ½:**

| Component | Thá»i gian |
|-----------|-----------|
| **Bi-Encoder Retrieval** | 50-100ms |
| **Cross-Encoder Reranking** | 200-500ms |
| **Total Pipeline** | 250-600ms |

## ğŸ› ï¸ **DEVELOPMENT**

### **CÃ i Ä‘áº·t development dependencies:**

```bash
pip install -e .[dev]
```

### **Cháº¡y tests:**

```bash
# Unit tests
pytest tests/

# Integration tests
pytest tests/integration/

# Performance tests
pytest tests/performance/
```

### **Code formatting:**

```bash
# Format code
black .

# Lint code
flake8 .

# Type checking
mypy .
```

## ğŸ“š **API DOCUMENTATION**

### **LegalQAPipeline**

Class chÃ­nh Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i há»‡ thá»‘ng.

```python
from core.pipeline import LegalQAPipeline

# Khá»Ÿi táº¡o
pipeline = LegalQAPipeline()

# Kiá»ƒm tra tráº¡ng thÃ¡i
if pipeline.is_ready:
    print("Pipeline sáºµn sÃ ng!")
else:
    print("Pipeline chÆ°a sáºµn sÃ ng!")
```

#### **Methods:**

##### `predict(query, top_k_retrieval=100, top_k_final=5)`

Dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i cho cÃ¢u há»i.

**Parameters:**
- `query` (str): CÃ¢u há»i cáº§n tráº£ lá»i
- `top_k_retrieval` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£ retrieval (default: 100)
- `top_k_final` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£ cuá»‘i cÃ¹ng (default: 5)

**Returns:**
- `List[Dict]`: Danh sÃ¡ch káº¿t quáº£ vá»›i format:
  ```python
  [
      {
          "aid": "law_1_113",
          "content": "Äiá»u 113: NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
          "retrieval_score": 0.85,
          "rerank_score": 0.92
      },
      # ...
  ]
  ```

**VÃ­ dá»¥ sá»­ dá»¥ng:**
```python
# Input
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"

# Output
results = [
    {
        "aid": "law_1_113",
        "content": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm 12 ngÃ y lÃ m viá»‡c...",
        "retrieval_score": 0.85,
        "rerank_score": 0.92
    },
    {
        "aid": "law_1_114",
        "content": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm Ä‘Æ°á»£c tÃ­nh theo nÄƒm lÃ m viá»‡c...",
        "retrieval_score": 0.78,
        "rerank_score": 0.87
    }
]
```

**VÃ­ dá»¥ sá»­ dá»¥ng:**
```python
# Input
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"

# Output
results = [
    {
        "aid": "law_1_113",
        "content": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm 12 ngÃ y lÃ m viá»‡c...",
        "retrieval_score": 0.85,
        "rerank_score": 0.92
    },
    {
        "aid": "law_1_114",
        "content": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm Ä‘Æ°á»£c tÃ­nh theo nÄƒm lÃ m viá»‡c...",
        "retrieval_score": 0.78,
        "rerank_score": 0.87
    }
]
```

##### `retrieve(query, top_k=100)`

Chá»‰ thá»±c hiá»‡n retrieval (táº§ng 1).

**Parameters:**
- `query` (str): CÃ¢u há»i
- `top_k` (int): Sá»‘ lÆ°á»£ng káº¿t quáº£

**Returns:**
- `Tuple[List[str], List[float]]`: (aids, scores)

**VÃ­ dá»¥:**
```python
# Input
query = "Äiá»u kiá»‡n thÃ nh láº­p doanh nghiá»‡p?"

# Output
aids = ["law_2_15", "law_2_16", "law_2_17", ...]
scores = [0.95, 0.87, 0.82, ...]
```

**VÃ­ dá»¥:**
```python
# Input
query = "Äiá»u kiá»‡n thÃ nh láº­p doanh nghiá»‡p?"

# Output
aids = ["law_2_15", "law_2_16", "law_2_17", ...]
scores = [0.95, 0.87, 0.82, ...]
```

##### `rerank(query, retrieved_aids, retrieved_distances)`

Chá»‰ thá»±c hiá»‡n reranking (táº§ng 2).

**Parameters:**
- `query` (str): CÃ¢u há»i
- `retrieved_aids` (List[str]): Danh sÃ¡ch AIDs tá»« retrieval
- `retrieved_distances` (List[float]): Äiá»ƒm sá»‘ tá»« retrieval

**Returns:**
- `List[Dict]`: Káº¿t quáº£ Ä‘Ã£ rerank

**VÃ­ dá»¥:**
```python
# Input
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
retrieved_aids = ["law_1_113", "law_1_114", "law_1_115"]
retrieved_distances = [0.85, 0.78, 0.72]

# Output
reranked_results = [
    {
        "aid": "law_1_113",
        "content": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
        "retrieval_score": 0.85,
        "rerank_score": 0.92
    },
    {
        "aid": "law_1_114", 
        "content": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm...",
        "retrieval_score": 0.78,
        "rerank_score": 0.87
    }
]
```

**VÃ­ dá»¥:**
```python
# Input
query = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"
retrieved_aids = ["law_1_113", "law_1_114", "law_1_115"]
retrieved_distances = [0.85, 0.78, 0.72]

# Output
reranked_results = [
    {
        "aid": "law_1_113",
        "content": "Äiá»u 113. NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm...",
        "retrieval_score": 0.85,
        "rerank_score": 0.92
    },
    {
        "aid": "law_1_114", 
        "content": "Äiá»u 114. Thá»i gian nghá»‰ phÃ©p nÄƒm...",
        "retrieval_score": 0.78,
        "rerank_score": 0.87
    }
]
```

## ğŸš¨ **TROUBLESHOOTING**

### **Lá»—i thÆ°á»ng gáº·p:**

#### **1. "ModuleNotFoundError: No module named 'config'"**

**NguyÃªn nhÃ¢n:** Python path khÃ´ng Ä‘Ãºng.

**Giáº£i phÃ¡p:**
```bash
# ThÃªm project root vÃ o PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/path/to/lawbot"

# Hoáº·c cháº¡y tá»« project root
cd /path/to/lawbot
python scripts/01_check_environment.py
```

#### **2. "CUDA out of memory"**

**NguyÃªn nhÃ¢n:** GPU memory khÃ´ng Ä‘á»§.

**Giáº£i phÃ¡p:**
```bash
# Giáº£m batch size
export LAWBOT_BI_ENCODER_BATCH_SIZE=2
export LAWBOT_CROSS_ENCODER_BATCH_SIZE=1

# Hoáº·c sá»­ dá»¥ng CPU
export CUDA_VISIBLE_DEVICES=""
```

#### **3. "File not found: data/raw/legal_corpus.json"**

**NguyÃªn nhÃ¢n:** File dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c táº£i.

**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra cáº¥u trÃºc thÆ° má»¥c
ls -la data/raw/

# Táº£i dá»¯ liá»‡u náº¿u cáº§n
python scripts/download_data.py
```

#### **4. "Model did not return a loss"**

**NguyÃªn nhÃ¢n:** Cross-Encoder training configuration sai.

**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra labels trong training data
python scripts/debug_training_data.py

# Cháº¡y láº¡i training vá»›i config Ä‘Ãºng
python scripts/11_train_cross_encoder.py
```

### **Debug mode:**

```bash
# Báº­t debug mode
export LAWBOT_DEBUG=true

# Cháº¡y vá»›i logging chi tiáº¿t
python run_pipeline.py --step 01
```

## ğŸ“– **TÃ€I LIá»†U THAM KHáº¢O**

### **Papers:**
- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)
- [Cross-Encoders vs. Bi-Encoders for Zero-Shot Classification](https://arxiv.org/abs/2108.08877)
- [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906)

### **Libraries:**
- [Sentence Transformers](https://www.sbert.net/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Transformers](https://huggingface.co/transformers/)
- [PyTorch](https://pytorch.org/)

### **Datasets:**
- [Vietnamese Legal Corpus](https://github.com/lawbot-team/vietnamese-legal-corpus)
- [Legal QA Dataset](https://github.com/lawbot-team/legal-qa-dataset)

## ğŸ¤ **CONTRIBUTING**

ChÃºng tÃ´i ráº¥t hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p! Vui lÃ²ng Ä‘á»c [CONTRIBUTING.md](CONTRIBUTING.md) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

### **CÃ¡ch Ä‘Ã³ng gÃ³p:**

1. **Fork** repository
2. **Táº¡o** feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** changes (`git commit -m 'Add amazing feature'`)
4. **Push** to branch (`git push origin feature/amazing-feature`)
5. **Táº¡o** Pull Request

### **Guidelines:**

- âœ… TuÃ¢n thá»§ PEP 8 style guide
- âœ… Viáº¿t tests cho tÃ­nh nÄƒng má»›i
- âœ… Cáº­p nháº­t documentation
- âœ… Kiá»ƒm tra code vá»›i linter

## ğŸ“„ **LICENSE**

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c cáº¥p phÃ©p theo MIT License - xem file [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ“ **LIÃŠN Há»†**

- **Email:** lawbot@example.com
- **GitHub:** [@lawbot-team](https://github.com/lawbot-team)
- **Documentation:** [https://lawbot.readthedocs.io/](https://lawbot.readthedocs.io/)
- **Issues:** [https://github.com/lawbot-team/lawbot/issues](https://github.com/lawbot-team/lawbot/issues)

## ğŸ™ **ACKNOWLEDGMENTS**

- **BKAI Foundation** cho Vietnamese Bi-Encoder model
- **VINAI** cho PhoBERT model
- **Facebook Research** cho FAISS library
- **Hugging Face** cho Transformers library

---

**Made with â¤ï¸ by LawBot Team**
