import streamlit as st
import sys
import os
import json
import random
import time
import gc
from typing import List, Dict, Optional, Tuple
import pandas as pd

# Them thu muc goc vao path de import
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
import config
from core.pipeline import LegalQAPipeline


@st.cache_data(ttl=3600)  # Cache for 1 hour
def load_random_questions() -> Tuple[List[str], List[str]]:
    """
    Load random questions from training and test datasets
    Returns: (training_questions, test_questions)
    """
    training_questions = []
    test_questions = []

    try:
        # Load training questions
        train_file = os.path.join(config.DATA_DIR, "train.json")
        if os.path.exists(train_file):
            with open(train_file, "r", encoding="utf-8") as f:
                train_data = json.load(f)
                training_questions = [
                    item.get("question", "")
                    for item in train_data
                    if item.get("question")
                ]

        # Load test questions
        test_file = os.path.join(config.DATA_DIR, "public_test.json")
        if os.path.exists(test_file):
            with open(test_file, "r", encoding="utf-8") as f:
                test_data = json.load(f)
                test_questions = [
                    item.get("question", "")
                    for item in test_data
                    if item.get("question")
                ]

    except Exception as e:
        st.warning(f"KhÃ´ng thá»ƒ load cÃ¢u há»i tá»« datasets: {e}")

    return training_questions, test_questions


@st.cache_resource(ttl=1800)  # Cache for 30 minutes
def load_pipeline(force_cpu=False):
    """Tai va cache pipeline de tranh load lai moi lan tuong tac."""
    try:
        # Set CUDA environment variables to avoid issues
        import os

        os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

        # Force CPU if requested
        if force_cpu:
            os.environ["CUDA_VISIBLE_DEVICES"] = ""
            st.info("Äang sá»­ dá»¥ng CPU mode")

        # Memory cleanup before loading
        gc.collect()

        start_time = time.time()
        pipeline = LegalQAPipeline()
        load_time = time.time() - start_time

        if not pipeline.is_ready:
            st.error(
                "Loi khoi tao Pipeline. Vui long kiem tra logs o terminal de biet chi tiet."
            )
            st.warning(
                "Hay chac chan rang ban da huan luyen cac mo hinh va dat chung vao thu muc 'models', sau do chay 'scripts/04_build_faiss_index.py'."
            )
            return None

        st.success(f"âœ… Pipeline loaded successfully in {load_time:.2f}s")
        return pipeline

    except Exception as e:
        st.error(f"Lá»—i khá»Ÿi táº¡o pipeline: {e}")
        st.info("Thá»­ khá»Ÿi Ä‘á»™ng láº¡i app hoáº·c kiá»ƒm tra logs")
        return None


def calculate_optimal_parameters(
    final_results_count: int, search_aggressiveness: str = "balanced"
) -> Dict[str, int]:
    """
    TÃ­nh toÃ¡n cÃ¡c tham sá»‘ tá»‘i Æ°u cho táº§ng 1 vÃ  táº§ng 2 dá»±a trÃªn sá»‘ káº¿t quáº£ cuá»‘i cÃ¹ng
    vÃ  má»©c Ä‘á»™ aggressive cá»§a tÃ¬m kiáº¿m
    """
    # Multiplier based on search aggressiveness
    multipliers = {
        "conservative": {"retrieval": 10, "light": 3},
        "balanced": {"retrieval": 20, "light": 4},
        "aggressive": {"retrieval": 30, "light": 6},
    }

    mult = multipliers.get(search_aggressiveness, multipliers["balanced"])

    # Táº§ng 1 (Retrieval): Láº¥y nhiá»u hÆ¡n Ä‘á»ƒ cÃ³ Ä‘á»§ candidate cho táº§ng 2
    top_k_retrieval = max(50, final_results_count * mult["retrieval"])

    # Táº§ng 2 (Light Reranking): Láº¥y vá»«a Ä‘á»§ Ä‘á»ƒ táº§ng 3 cÃ³ thá»ƒ xá»­ lÃ½
    top_k_light_reranking = max(20, final_results_count * mult["light"])

    return {
        "top_k_retrieval": top_k_retrieval,
        "top_k_light_reranking": top_k_light_reranking,
        "top_k_final": final_results_count,
    }


def get_random_question(questions: List[str], question_type: str) -> str:
    """Get a random question from the specified list"""
    if not questions:
        return f"KhÃ´ng cÃ³ cÃ¢u há»i {question_type} nÃ o"
    return random.choice(questions)


def display_performance_metrics(start_time: float, end_time: float, results_count: int):
    """Display performance metrics"""
    duration = end_time - start_time

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("â±ï¸ Thá»i gian xá»­ lÃ½", f"{duration:.2f}s")
    with col2:
        st.metric("ğŸ“Š Káº¿t quáº£ tÃ¬m tháº¥y", results_count)
    with col3:
        if duration > 0:
            st.metric("âš¡ Tá»‘c Ä‘á»™", f"{results_count/duration:.1f} káº¿t quáº£/s")


# Page configuration
st.set_page_config(
    page_title="Há»‡ thá»‘ng Há»i-ÄÃ¡p PhÃ¡p luáº­t",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Main title
st.title("ğŸ›ï¸ Há»‡ thá»‘ng Há»i-ÄÃ¡p PhÃ¡p luáº­t Viá»‡t Nam")
st.markdown(
    "Nháº­p má»™t cÃ¢u há»i vá» phÃ¡p luáº­t vÃ  há»‡ thá»‘ng sáº½ cá»‘ gáº¯ng tÃ¬m nhá»¯ng Ä‘iá»u luáº­t liÃªn quan nháº¥t."
)

# Load random questions
training_questions, test_questions = load_random_questions()

# Sidebar configuration
with st.sidebar:
    st.header("âš™ï¸ CÃ i Ä‘áº·t há»‡ thá»‘ng")

    # Device selection
    force_cpu = st.checkbox("ğŸ–¥ï¸ Force sá»­ dá»¥ng CPU (náº¿u cÃ³ lá»—i CUDA)", value=False)

    # Performance settings
    st.subheader("ğŸš€ CÃ i Ä‘áº·t hiá»‡u suáº¥t")
    search_aggressiveness = st.selectbox(
        "Má»©c Ä‘á»™ tÃ¬m kiáº¿m",
        options=["conservative", "balanced", "aggressive"],
        index=1,
        help="Conservative: Nhanh hÆ¡n, Ã­t káº¿t quáº£ hÆ¡n. Aggressive: Cháº­m hÆ¡n, nhiá»u káº¿t quáº£ hÆ¡n",
    )

    # Results customization
    st.subheader("ğŸ”§ TÃ¹y chá»n káº¿t quáº£")
    final_results_count = st.slider(
        "Sá»‘ káº¿t quáº£ cuá»‘i cÃ¹ng",
        min_value=1,
        max_value=50,
        value=5,
        step=1,
        help="Sá»‘ lÆ°á»£ng Ä‘iá»u luáº­t sáº½ hiá»ƒn thá»‹ trong káº¿t quáº£ cuá»‘i cÃ¹ng",
    )

    # Random question feature
    st.subheader("ğŸ² CÃ¢u há»i ngáº«u nhiÃªn")
    if training_questions or test_questions:
        question_source = st.selectbox(
            "Chá»n nguá»“n cÃ¢u há»i",
            options=["Training Dataset", "Test Dataset", "Cáº£ hai"],
            help="CÃ¢u há»i tá»« training dataset thÆ°á»ng Ä‘a dáº¡ng hÆ¡n",
        )

        if st.button("ğŸ² Láº¥y cÃ¢u há»i ngáº«u nhiÃªn"):
            if question_source == "Training Dataset" and training_questions:
                random_q = get_random_question(training_questions, "training")
                st.session_state.random_question = random_q
            elif question_source == "Test Dataset" and test_questions:
                random_q = get_random_question(test_questions, "test")
                st.session_state.random_question = random_q
            elif question_source == "Cáº£ hai":
                all_questions = training_questions + test_questions
                random_q = get_random_question(all_questions, "combined")
                st.session_state.random_question = random_q
            else:
                st.warning("KhÃ´ng cÃ³ cÃ¢u há»i nÃ o trong dataset Ä‘Ã£ chá»n")
    else:
        st.info("ğŸ“ KhÃ´ng tÃ¬m tháº¥y datasets Ä‘á»ƒ load cÃ¢u há»i ngáº«u nhiÃªn")

# Architecture info
with st.expander("â„¹ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng (3 táº§ng)"):
    st.markdown(
        """
    **ğŸ¯ Táº§ng 1 - Bi-Encoder Retrieval:** TÃ¬m kiáº¿m nhanh á»©ng viÃªn ban Ä‘áº§u  
    **âš¡ Táº§ng 2 - Light Reranker:** Lá»c xuá»‘ng á»©ng viÃªn cháº¥t lÆ°á»£ng cao  
    **ğŸ¯ Táº§ng 3 - Cross-Encoder Reranking:** Xáº¿p háº¡ng chÃ­nh xÃ¡c káº¿t quáº£ cuá»‘i cÃ¹ng
    """
    )

# Load pipeline
pipeline = load_pipeline(force_cpu=force_cpu)

if pipeline:
    # Query input with random question support
    default_question = "NgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p bao nhiÃªu ngÃ y?"

    # Use random question if available
    if hasattr(st.session_state, "random_question"):
        default_question = st.session_state.random_question
        # Clear the random question after use
        del st.session_state.random_question

    query = st.text_input(
        "Nháº­p cÃ¢u há»i cá»§a báº¡n:",
        value=default_question,
        help="Nháº­p cÃ¢u há»i vá» phÃ¡p luáº­t hoáº·c sá»­ dá»¥ng tÃ­nh nÄƒng cÃ¢u há»i ngáº«u nhiÃªn",
    )

    if st.button("ğŸ” TÃ¬m kiáº¿m", type="primary"):
        if query:
            # Calculate optimal parameters
            params = calculate_optimal_parameters(
                final_results_count, search_aggressiveness
            )

            # Display calculated parameters
            with st.expander("ğŸ“Š ThÃ´ng sá»‘ tÃ¬m kiáº¿m Ä‘Æ°á»£c tÃ­nh toÃ¡n tá»± Ä‘á»™ng"):
                st.markdown(
                    f"**ğŸ¯ Táº§ng 1 - Retrieval:** {params['top_k_retrieval']} á»©ng viÃªn"
                )
                st.markdown(
                    f"**âš¡ Táº§ng 2 - Light Reranking:** {params['top_k_light_reranking']} á»©ng viÃªn"
                )
                st.markdown(
                    f"**ğŸ¯ Táº§ng 3 - Final Reranking:** {params['top_k_final']} káº¿t quáº£ cuá»‘i cÃ¹ng"
                )
                st.markdown(f"**âš™ï¸ Má»©c Ä‘á»™ tÃ¬m kiáº¿m:** {search_aggressiveness}")

            # Performance monitoring
            start_time = time.time()

            with st.spinner("ğŸ”„ Äang tÃ¬m kiáº¿m vÃ  xáº¿p háº¡ng cÃ¡c Ä‘iá»u luáº­t..."):
                try:
                    results = pipeline.predict(
                        query=query,
                        top_k_retrieval=params["top_k_retrieval"],
                        top_k_final=params["top_k_final"],
                        top_k_light_reranking=params["top_k_light_reranking"],
                    )

                    end_time = time.time()

                    # Display performance metrics
                    display_performance_metrics(
                        start_time, end_time, len(results) if results else 0
                    )

                except Exception as e:
                    st.error(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh tÃ¬m kiáº¿m: {e}")
                    st.info("ğŸ’¡ Thá»­ giáº£m sá»‘ lÆ°á»£ng káº¿t quáº£ hoáº·c chuyá»ƒn sang CPU mode")
                    results = None

            if results is not None:
                st.success("âœ… HoÃ n thÃ nh!")

            if not results:
                st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p.")
                st.info("ğŸ’¡ Thá»­ sá»­ dá»¥ng tá»« khÃ³a khÃ¡c hoáº·c tÄƒng má»©c Ä‘á»™ tÃ¬m kiáº¿m")
            else:
                st.subheader(f"ğŸ“‹ Top {len(results)} káº¿t quáº£ liÃªn quan nháº¥t:")

                # Create tabs for different views
                tab1, tab2 = st.tabs(["ğŸ“„ Xem chi tiáº¿t", "ğŸ“Š So sÃ¡nh Ä‘iá»ƒm sá»‘"])

                with tab1:
                    for i, res in enumerate(results):
                        with st.expander(
                            f"**Káº¿t quáº£ {i+1}: Äiá»u {res['aid']}** (Äiá»ƒm: {res['rerank_score']:.4f})"
                        ):
                            st.markdown(f"**ğŸ“„ Ná»™i dung:**")
                            st.write(res["content"])
                            st.markdown(f"---")
                            st.markdown(
                                f"**ğŸ¯ Äiá»ƒm Retrieval (Táº§ng 1):** {res['retrieval_score']:.4f}"
                            )
                            st.markdown(
                                f"**âš¡ Äiá»ƒm Re-rank (Táº§ng 3):** {res['rerank_score']:.4f}"
                            )
                            st.markdown(
                                f"**ğŸ“Š Tá»•ng Ä‘iá»ƒm:** {(res['retrieval_score'] + res['rerank_score']) / 2:.4f}"
                            )

                with tab2:
                    # Create comparison chart
                    if results:
                        df = pd.DataFrame(
                            [
                                {
                                    "Káº¿t quáº£": f"Äiá»u {res['aid']}",
                                    "Retrieval Score": res["retrieval_score"],
                                    "Rerank Score": res["rerank_score"],
                                    "Tá»•ng Ä‘iá»ƒm": (
                                        res["retrieval_score"] + res["rerank_score"]
                                    )
                                    / 2,
                                }
                                for res in results
                            ]
                        )

                        st.bar_chart(
                            df.set_index("Káº¿t quáº£")[["Retrieval Score", "Rerank Score"]]
                        )

                        # Display summary statistics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(
                                "Äiá»ƒm cao nháº¥t",
                                f"{max([r['rerank_score'] for r in results]):.4f}",
                            )
                        with col2:
                            st.metric(
                                "Äiá»ƒm tháº¥p nháº¥t",
                                f"{min([r['rerank_score'] for r in results]):.4f}",
                            )
                        with col3:
                            avg_score = sum([r["rerank_score"] for r in results]) / len(
                                results
                            )
                            st.metric("Äiá»ƒm trung bÃ¬nh", f"{avg_score:.4f}")
        else:
            st.warning("âš ï¸ Vui lÃ²ng nháº­p má»™t cÃ¢u há»i.")
else:
    st.header("ğŸš¨ Pipeline chÆ°a sáºµn sÃ ng")
    st.info(
        "âš ï¸ Vui lÃ²ng kiá»ƒm tra terminal Ä‘á»ƒ biáº¿t lÃ½ do lá»—i vÃ  Ä‘áº£m báº£o cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c chuáº©n bá»‹."
    )
